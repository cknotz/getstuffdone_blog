{
  "hash": "e235cb571850b5ed020449fb057079e5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Prompt engineering\"\ndescription: \"How to *effectively* use ChatGPT as a coding assistant for R\"\nauthor: \"Carlo Knotz\"\ndraft: true\ndate: \"2025-05-15\"\nformat:\n  html:\n    toc: true\nlightbox: true\ncategories:\n  - LLMs\n  - ChatGPT\n  - Prompt engineering\n---\n\n\n\n\n\n## `R` & *ChatGPT*\n\nEveryone knows it, people are shouting it from the rooftops: *ChatGPT* and other large language models (LLMs) can code. Languages they can write code in include `HTML`, `CSS`, and `Javascript`, `Python` --- and `R`!\n\nOf course, *ChatGPT* *can* also give you answers that are wrong or simply not useful, including when it comes to coding. Some of this has to do with how LLMs work --- they are basically very complicated statistical models that make educated guesses about sequences of words. Their guesses are highly educated, given that they were trained on a large amount of text, but they are nevertheless guesses, and guesses can be wrong.\n\nBut often, the difference between a useful and correct and a useless or wrong answer has to do with **effective prompt engineering**: Giving *ChatGPT* instructions that let it produce the desired result in as few steps as possible.\n\n*OpenAI* have a dedicated, but general, [guide for effective prompting](https://platform.openai.com/docs/guides/text), but it is not always self-evident how these things apply to prompting for a coding language like `R`, especially to someone who might just have started learning `R` or some other coding language. Therefore, this post provides guidance on how to give language models effective prompts for solving `R` coding problems (that may also apply to other coding languages).\n\n\n## Assistants & bosses\n\nAs a general rule, I found that to effectively use *ChatGPT*, you need to see yourself as someone who delegates a task to an assistant: Basically, a boss.\n\nAs anyone who has ever had a boss can confirm, delegation works better the more competent, informed, and experienced the boss is --- basically, the boss *could* in principle also do the thing they are asking their assistant to do, but they need to focus on other things and therefore delegate some stuff to the assistant. In that case, the boss:\n\n a) has a reasonably clear understanding of what the problem is;\n b) has a reasonably clear idea of how the solution or end result is supposed to look like;\n c) has a reasonably clear idea of how to get from problem to solution; what is, and what is not, feasible and makes most sense;\n d) can use this knowledge to give precise, explicit, and detailed instructions to their assistant;\n\nOn the other hand, this guy below is unlikely to be more than a source of endless frustration to their assistant and a waste of their company's time:\n\n![Everyone's dream boss](thumbnail.jpg)\n\n::: {.callout-tip title = \"Therefore:\"}\n\n**To make effective use of *ChatGPT*, be as different from this guy as humanly possible.**\n\n:::\n\n## Effective prompt engineering and what you need to know to do it\n\n### Roles\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1+ 1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2\n```\n\n\n:::\n:::\n\n\n\n\n\n@Jansenetal2025\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}