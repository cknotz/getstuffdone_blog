[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About this blog",
    "section": "",
    "text": "Hi!\nMy name is Carlo and I teach political science, including data analysis, at the University of Stavanger in Norway.\nI often find that students have quite smart ideas that they want to test in a course paper or thesis project and which could be tested with a relatively simple quantitative analysis – but they don’t know how to actually go about this (and might also be intimidated by quantitative methods/coding).\nThe aim of this blog is to show these students how they can test big ideas – e.g., about the role of class, social norms, political institutions, or gender – with relatively simple methods that they should be familiar with from their introductory statistics course and with the free and open-source R statistical programming language.\nThe posts are very much focussed on explaining the general logic of an analysis and assume that readers are at least a bit familiar with the basic of statistics and data analysis methods and how to work with R. Each post also gives pointers to more advanced resources (textbooks, journal articles) on quantitative methods."
  },
  {
    "objectID": "posts/globalization/index.html",
    "href": "posts/globalization/index.html",
    "title": "How vulnerable are workers to globalization (and what effects does this have)?",
    "section": "",
    "text": "‘Globalization destroys jobs’ or similar statements are often made by politicians or business and labor leaders, especially when new trade agreements are in the process of being negotiated. And indeed, even though free trade is generally beneficial to countries’ economies as a whole, there are usually some workers who are negatively affected by increased competition from abroad (Autor, Dorn, and Hanson 2013; Heckscher 1919; Ohlin 1933). These negative economic effects can then also have further political and social effects, for example in the form of increased demands for social protection (Walter 2010), increased political polarization and conflict (Autor et al. 2020), and rising rates of divorce and out-of-wedlock births (Anelli, Giuntella, and Stella 2024).\nTo be able to study these (and potentially other) effects, researchers obviously need some of measurement of how exposed and vulnerable workers are to the negative effects of trade and international competition. One way to measure this is with indicators of ‘offshoreability’ — how easy or difficult is it to move the work done by people in different occupations to other countries? Different such indicators have been developed, but one that is relatively widely used are the indicators of offshoreability by Blinder & Krueger (2013). They use a survey-based approach, where they ask workers about their perceptions of how easy it would be to move their jobs abroad and confirm this with a second survey of experts.\nThe rest of this post will show you how you can access the data, import them into R, and merge them with data from round 7 (2014) of the European Social Survey so that you can analyze how vulnerability to globalization affects people’s attitudes and behavior."
  },
  {
    "objectID": "posts/globalization/index.html#the-losers-of-globalization-and-trade",
    "href": "posts/globalization/index.html#the-losers-of-globalization-and-trade",
    "title": "How vulnerable are workers to globalization (and what effects does this have)?",
    "section": "",
    "text": "‘Globalization destroys jobs’ or similar statements are often made by politicians or business and labor leaders, especially when new trade agreements are in the process of being negotiated. And indeed, even though free trade is generally beneficial to countries’ economies as a whole, there are usually some workers who are negatively affected by increased competition from abroad (Autor, Dorn, and Hanson 2013; Heckscher 1919; Ohlin 1933). These negative economic effects can then also have further political and social effects, for example in the form of increased demands for social protection (Walter 2010), increased political polarization and conflict (Autor et al. 2020), and rising rates of divorce and out-of-wedlock births (Anelli, Giuntella, and Stella 2024).\nTo be able to study these (and potentially other) effects, researchers obviously need some of measurement of how exposed and vulnerable workers are to the negative effects of trade and international competition. One way to measure this is with indicators of ‘offshoreability’ — how easy or difficult is it to move the work done by people in different occupations to other countries? Different such indicators have been developed, but one that is relatively widely used are the indicators of offshoreability by Blinder & Krueger (2013). They use a survey-based approach, where they ask workers about their perceptions of how easy it would be to move their jobs abroad and confirm this with a second survey of experts.\nThe rest of this post will show you how you can access the data, import them into R, and merge them with data from round 7 (2014) of the European Social Survey so that you can analyze how vulnerability to globalization affects people’s attitudes and behavior."
  },
  {
    "objectID": "posts/globalization/index.html#accessing-the-data",
    "href": "posts/globalization/index.html#accessing-the-data",
    "title": "How vulnerable are workers to globalization (and what effects does this have)?",
    "section": "Accessing the data",
    "text": "Accessing the data\nLuckily, the Blinder/Krueger data are publicly available as part of the replication data package of a second (important) research article, which compares the effects of globalization and technological change on workers (Goos, Manning, and Salomons 2014). Goos et al. have archived the research data they use in the ICPSR Data Archive: https://doi.org/10.3886/E112846V1. There, under Data, is the task.dta dataset, which contains the offshoreability scores and, as a bonus, also additional scores on how exposed workers are to losing their jobs to robots and other automated technology (from Autor, Levy, and Murnane 2003; used by e.g., Thewissen and Rueda 2019). You can download the dataset for free, after a quick login."
  },
  {
    "objectID": "posts/globalization/index.html#importing-and-merging-the-data-with-ess-data",
    "href": "posts/globalization/index.html#importing-and-merging-the-data-with-ess-data",
    "title": "How vulnerable are workers to globalization (and what effects does this have)?",
    "section": "Importing and merging the data with ESS data",
    "text": "Importing and merging the data with ESS data\n\nPreparation\nMerging the data with ESS survey data is not as difficult as it might seem. The first step is to make sure that you also have access to ESS data (which can be downloaded for free from europeansocialsurvey.org), and that both datasets are stored in your current working directly (“folder”) so that R can directly find and import them. As mentioned above, the example here uses data from the 7th ESS round, so if you do not already have the data on your computer, quickly download them (in Stata/.dta format).\nIn R, we first load the tidyverse because it contains functions that we need to be able to work with and visualize the data. I am also setting the ggplot theme to classic:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntheme_set(theme_classic())\n\n\n\nData import\nThen we first import the ESS dataset with haven:\n\ness7 &lt;- haven::read_dta(\"ess7.dta\")\n\nThe ESS is quite big, so to make things easier we select only a few variables that we want to work with:\n\ness7 %&gt;% \n  select(idno,cntry,essround,isco08,gndr,agea,trstplt) -&gt; ess7\n\n\nidno and essround are “administrative” variables that are always good to keep\ncntry designates which country a given respondent comes from, and this one should always be kept\nisco08 is the respondents’ occupation as measured by the 2008 version of the International Standard Classification of Occupations (ISCO; see also the other post on measuring class). This variable is important because we will use it to link the ESS data with the vulnerability indicator data\nagea, gndr, and trstplt measure the respondents’ age, gender, and their trust in politicans (on a 0-10 scale)\n\nNext, we import the vulnerability indicator scores:\n\nscores &lt;- haven::read_dta(\"task.dta\")\n\n\n\nA quick exploration\nIt is time to take a quick look at the data to get a sense of what we are working with:\n\nhead(scores)\n\n# A tibble: 6 × 7\n  occupation           RTI_alm_isco_77     BK OFF1_ffl OFF2_ffl OFF3_ffl OFF_gms\n  &lt;dbl+lbl&gt;                      &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 12 [Corporate manag…          -0.747 -0.320   -1.43     0.798   -1.66   -0.593\n2 13 [Managers of sma…          -1.52  -0.634   -0.937    0.265   -1.19   -0.593\n3 21 [Physical, mathe…          -0.822  1.05     0.390    0.798   -1.48   -0.375\n4 22 [Life science an…          -1.00  -0.758   -1.92     0.544   -1.70   -0.639\n5 24 [Other professio…          -0.732  0.212   -0.892    1.56    -1.18   -0.513\n6 31 [Physical, mathe…          -0.397 -0.123    0.116   -0.393   -0.433  -0.272\n\n\nYou might notice that every row in the dataset is an occupation: Row #1 is “Corporate managers”, row #2 is “Managers of small enterprises”, and so on. The first column (or variable) indicates the title of the occupation and a 2-digit code based on the 1988 version of the International Standard Classifiation of Occupations (ISCO) classification, where “Corporate managers” have the code 12.1 The other variables are different indicators of vulnerability:\n\nRTI_alm_isco_77 is an indicator of vulnerability to automation (“routine task intensity”) that was developed by Autor, Levy, and Murnane (2003);\nBK is the indicator of offshoreability by Blinder & Krueger (2013);\nOFF1_ffl to OFF3_ffl are alternative indicators of offshoreability by Firpo et al. (see their paper for details: Firpo, Fortin, and Lemieux 2011);\nOFF_gms is the BK indicator in a normalized (“rescaled”) version;\n\nLet’s take a closer look at the BK indicator:\n\nsummary(scores$BK)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-0.9985 -0.7585 -0.3203  0.0000  0.3996  2.3458 \n\n\nThe indicator ranges from (almost) -1 to 2.35 and is centered on 0. Maybe more interesting is to see which occupations are particularly exposed to globalization. To see that, we reorder the data from the highest to lowest BK score and let R display the five highest-scoring occupations:\n\nscores %&gt;% \n  arrange(-BK) %&gt;% \n  head()\n\n# A tibble: 6 × 7\n  occupation            RTI_alm_isco_77    BK OFF1_ffl OFF2_ffl OFF3_ffl OFF_gms\n  &lt;dbl+lbl&gt;                       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 82 [Machine operator…           0.493 2.35     1.66    -1.02   0.993     3.18 \n2 73 [Precision, handi…           1.59  1.66     0.585   -0.564  0.00830  -0.616\n3 81 [Stationary plant…           0.323 1.59     0.990   -1.41   0.306     1.63 \n4 74 [Other craft and …           1.24  1.15     1.49    -0.453  1.07     -0.272\n5 21 [Physical, mathem…          -0.822 1.05     0.390    0.798 -1.48     -0.375\n6 41 [Office clerks]              2.24  0.400    0.301    1.26   0.913     1.21 \n\n\nEvidently, typical manual or industrial occupations are the most vulnerable to globalization, but so are physicists and mathematicians!\nJust to complete the picture, we also look at the least exposed occupations:\n\nscores %&gt;% \n  arrange(BK) %&gt;% \n  head()\n\n# A tibble: 6 × 7\n  occupation           RTI_alm_isco_77     BK OFF1_ffl OFF2_ffl OFF3_ffl OFF_gms\n  &lt;dbl+lbl&gt;                      &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 83 [Drivers and mob…         -1.50   -0.999   0.399   -1.37     0.703   -0.628\n2 51 [Personal and pr…         -0.598  -0.937  -0.910    0.312    0.240   -0.639\n3 71 [Extraction and …         -0.185  -0.934   0.603   -1.23     0.0133  -0.593\n4 52 [Models, salespe…          0.0534 -0.893   0.0565   0.913    1.34    -0.639\n5 91 [Sales and servi…          0.0274 -0.808   0.729    0.0522   1.52    -0.375\n6 22 [Life science an…         -1.00   -0.758  -1.92     0.544   -1.70    -0.639\n\n\nHere, it is again some manual workers (e.g., drivers and builders) that top the list (or, rather, are at the bottom). However, salespersons and medical professionals, who obviously cannot do their jobs from abroad, also have low exposure to globalization.\n\n\nAdjusting the ISCO scores\nAs mentioned, the vulnerability score data are based on the ISCO-88 occupational classification, which is an older version of the ISCO-08 classifcation that is used to measure the occupation of ESS respondents. In addition, you may have noticed that the ISCO-scores in the ESS data have four numbers while those in the vulnerability data have two. The latter is because the vulnerability data use a simplified or less fine-grained version of the ISCO classification.\nThis means that to be able to merge the two datasets, we need to make sure that both use the same ISCO-classification so that we can match the different occupations, and that they are measured at the same level of detail.\nFortunately, there are methods to convert the scores back and forth between the different versions of the ISCO classification, and one of these is the occupar package (similar to the DIGCLASS package that is used in the the other post on measuring class). In case you do not already have it installed, you can do so by running the following in your Console:\n\nremotes::install_github(\"DiogoFerrari/occupar\")\n\nTechnically, we could either adjust the ISCO-08 scores in the ESS to match the ISCO-88 scores used in the other dataset, or the other way around, and the occupar package has functions to do both. The only important thing is that both datasets contain the same version of the ISCO classication.\nWe will use the isco08to88() function which, as the name suggests, converts ISCO-08 scores in the ESS to ISCO-88 scores, so that we can then match the ESS data and the vulnerability indicators along these scores and merge the two datasets. This function needs the numerical ISCO scores (not the titles of the occupations but the associated numbers).\nThis means that we need to extract the numerical scores from the ISCO-08 variable in the ESS. The following code does this and stores the converted scores into a new variable:\n\ness7 %&gt;% \n  mutate(isco08_scores = as.numeric(isco08)) -&gt; ess7\n\nWe can take a quick look at the data to see if the conversion worked:\n\nhead(ess7)\n\n# A tibble: 6 × 8\n   idno cntry essround isco08                gndr    agea  trstplt isco08_scores\n  &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl+lbl&gt;             &lt;dbl+l&gt; &lt;dbl&gt; &lt;dbl+l&gt;         &lt;dbl&gt;\n1     1 AT           7  7126 [Plumbers and … 1 [Mal… 51    3 [3]            7126\n2     2 AT           7  8312 [Railway brake… 1 [Mal… 67    3 [3]            8312\n3     3 AT           7 NA(a) [Not applicabl… 2 [Fem… 89    3 [3]              NA\n4     4 AT           7  7223 [Metal working… 1 [Mal… 32    0 [No …          7223\n5     5 AT           7  9321 [Hand packers]  2 [Fem… 56    0 [No …          9321\n6     6 AT           7  9321 [Hand packers]  2 [Fem… 67    0 [No …          9321\n\n\nIndeed, the function worked as intended. For example, it correctly extracted the ISCO-08 score 7126 for the “plumber” in row #1 and saved it as 7126 in the new variable.\nThis means we can now convert the new scores to the ISCO-88 classification:\n\ness7 %&gt;% \n  mutate(isco88 = occupar::isco08to88(isco08_scores)) -&gt; ess7\n\nIf we take another quick look at the dataset, you can see the new ISCO-88 scores in the last column; you may also notice that the scores are slightly different (for example, 9321 in the ISCO-08 classification is 9322 in the old one):\n\nhead(ess7)\n\n# A tibble: 6 × 9\n   idno cntry essround isco08         gndr    agea  trstplt isco08_scores isco88\n  &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl+lbl&gt;      &lt;dbl+l&gt; &lt;dbl&gt; &lt;dbl+l&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n1     1 AT           7  7126 [Plumbe… 1 [Mal… 51    3 [3]            7126   7136\n2     2 AT           7  8312 [Railwa… 1 [Mal… 67    3 [3]            8312   8312\n3     3 AT           7 NA(a) [Not ap… 2 [Fem… 89    3 [3]              NA     NA\n4     4 AT           7  7223 [Metal … 1 [Mal… 32    0 [No …          7223   7223\n5     5 AT           7  9321 [Hand p… 2 [Fem… 56    0 [No …          9321   9322\n6     6 AT           7  9321 [Hand p… 2 [Fem… 67    0 [No …          9321   9322\n\n\nThe almost last step in the data preparation is to “simplify” the new ISCO-88 scores in the ESS data to the same level of detail that the vulnerability data have. This is relatively easy, we simply “extract” the first two numbers of the four-number ISCO-scores.2 The following code does that:\n\ness7 %&gt;% \n  mutate(isco88_2d = as.numeric(substr(as.character(isco88), 1,2))) -&gt; ess7\n\nIn human language, this code first converts the isco88 variable to text (as.character()), then uses substr() to extract the first two items (“from 1 to 2”), and then converts the result back to numbers with as.numeric().\nIf we take a look at the final result (with variables re-arranged so that we can see them next to each other), we can confirm that all worked as it should:\n\ness7 %&gt;% \n  relocate(idno,cntry,essround,isco08,isco88,isco88_2d) %&gt;% \n  head()\n\n# A tibble: 6 × 10\n   idno cntry essround isco08             isco88 isco88_2d gndr    agea  trstplt\n  &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl+lbl&gt;           &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl+l&gt; &lt;dbl&gt; &lt;dbl+l&gt;\n1     1 AT           7  7126 [Plumbers a…   7136        71 1 [Mal… 51    3 [3]  \n2     2 AT           7  8312 [Railway br…   8312        83 1 [Mal… 67    3 [3]  \n3     3 AT           7 NA(a) [Not applic…     NA        NA 2 [Fem… 89    3 [3]  \n4     4 AT           7  7223 [Metal work…   7223        72 1 [Mal… 32    0 [No …\n5     5 AT           7  9321 [Hand packe…   9322        93 2 [Fem… 56    0 [No …\n6     6 AT           7  9321 [Hand packe…   9322        93 2 [Fem… 67    0 [No …\n# ℹ 1 more variable: isco08_scores &lt;dbl&gt;\n\n\nFinally, we quickly convert the ISCO-88 scores in the vulnerability dataset to a pure numerical score. We also give it the same name as the corresponding variable in the ESS dataset to make merging the two datasets more straightforward:\n\nscores %&gt;% \n  mutate(isco88_2d = as.numeric(occupation)) -&gt; scores\n\n\n\nMerging the datasets\nMerging two datasets can seem a bit daunting to beginners, but it is actually quite easy. The dplyr package has functions for so-called “mutating joins” (see https://dplyr.tidyverse.org/reference/mutate-joins.html), which in essence simply merge two datasets along one (or potentially more) “identifier” variable. As long as one has one (or more) variables that can directly match observations between datasets – which in our case is the two-number ISCO-88 score – one can use these functions to merge two datasets.\nUsually, the correct function to use to merge datasets is left_join(). In our case, we want to join the ESS dataset with the vulnerability scores dataset along the two-digit ISCO-88 scores, so we specify this in our code:\n\ness7 %&gt;% \n  left_join(scores, by = \"isco88_2d\") -&gt; ess7\n\nAnd that is it.\nIf we take a look at the relevant variables in the final dataset, we can see the vulnerability scores matched to the ESS data:\n\ness7 %&gt;% \n  select(idno,isco08,isco88_2d,BK,RTI_alm_isco_77) %&gt;% \n  head()\n\n# A tibble: 6 × 5\n   idno isco08                                  isco88_2d     BK RTI_alm_isco_77\n  &lt;dbl&gt; &lt;dbl+lbl&gt;                                   &lt;dbl&gt;  &lt;dbl&gt;           &lt;dbl&gt;\n1     1  7126 [Plumbers and pipe fitters]              71 -0.934          -0.185\n2     2  8312 [Railway brake, signal and switc…        83 -0.999          -1.50 \n3     3 NA(a) [Not applicable]                         NA NA              NA    \n4     4  7223 [Metal working machine tool sett…        72 -0.451           0.457\n5     5  9321 [Hand packers]                           93 -0.658           0.449\n6     6  9321 [Hand packers]                           93 -0.658           0.449\n\n\nYou see that respondent with ID number 1 (the plumber) has a BK offshorability score of -9.34 and also an automation-vulnerability (RTI) score of -0.185.\nAs a last step, we convert the final dataset to the traditional R format so that it is easier to work with later:\n\ness7 &lt;- labelled::unlabelled(ess7)"
  },
  {
    "objectID": "posts/globalization/index.html#vulnerability-to-globalization-gender-age-and-political-trust",
    "href": "posts/globalization/index.html#vulnerability-to-globalization-gender-age-and-political-trust",
    "title": "How vulnerable are workers to globalization (and what effects does this have)?",
    "section": "Vulnerability to globalization, gender, age, and political trust",
    "text": "Vulnerability to globalization, gender, age, and political trust\nWith the merged data in hand, we can now do lots of different analyses. For example, we could use the vulnerabiility scores in a regression analysis to see if they are related to some other variable. Just to illustrate this, we will do a few quick visual analyses of the relationships between the offshoreability scores and gender, age, and political trust.\nFor example, let’s see if men or women are on average more exposed to globalization:\n\ness7 %&gt;% \n  group_by(gndr) %&gt;% \n  summarise(avg_BK = mean(BK, na.rm = T)) %&gt;% \n  drop_na() %&gt;%\n  ggplot(aes(x = gndr, y = avg_BK)) +\n    geom_col()\n\n\n\n\n\n\n\n\nThere is only a tiny difference: Women are very slightly less exposed to globalization than men.\nNext, we can see if there is a relation to age. To do that, we can calculate the average age in a given occupation and relate that average age to the vulnerability score in a scatterplot. Note that we use geom_text() to add the occupation titles to the graph:\n\ness7 %&gt;% \n  group_by(occupation) %&gt;% \n  summarise(avg_age = mean(agea, na.rm = T),\n            avg_BK = mean(BK, na.rm = T)) %&gt;% \n  drop_na() %&gt;% \n  ggplot(aes(x = avg_age, y = avg_BK)) +\n    geom_point() +\n    geom_text(aes(label = occupation), vjust = 1, \n              color = \"grey\",\n              size = 3) +\n    geom_smooth(method = \"lm\", color = \"grey\", \n                linetype = \"dashed\", se = F) +\n    labs(x = \"Average age in occupational group\",\n         y = \"Average offshoreability\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThere does seem to be a positive relationship: Occupations where workers are older are also more exposed to globalization.\nFinally, let’s see if exposure to globalization has political effects by testing if there is a relationship to trust in politicians. We do this with a box plot:\n\ness7 %&gt;% \n  ggplot(aes(x = trstplt, y = BK)) +\n    geom_boxplot()\n\nWarning: Removed 8011 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nAt least based on this (admittedly) very quick and superficial look at the data, there does not seem to be a strong relationship."
  },
  {
    "objectID": "posts/globalization/index.html#next-steps",
    "href": "posts/globalization/index.html#next-steps",
    "title": "How vulnerable are workers to globalization (and what effects does this have)?",
    "section": "Next steps",
    "text": "Next steps\nEven if there is not link to political trust, maybe you can think of other variables that are measured in the ESS that globalization vulnerability could have an effect on? And maybe you can even think of macro-level variables that could make these effects stronger or weaker (and then use the other post to compare the effects of globalization vulnerability between two or more selected countries)?\nFinally, you can also merge the vulnerability scores to other survey datasets such as the ISSP or the Eurobarometer so long as the survey dataset contains ISCO occupation scores."
  },
  {
    "objectID": "posts/globalization/index.html#footnotes",
    "href": "posts/globalization/index.html#footnotes",
    "title": "How vulnerable are workers to globalization (and what effects does this have)?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee https://ilostat.ilo.org/methods/concepts-and-definitions/classification-occupation/ for details on the ISCO classification.↩︎\nThis works because the numbers reflect the hierarchical structure of the ISCO classification. If we cut off the last two numbers, we get to a higher level of aggregation. See https://ilostat.ilo.org/methods/concepts-and-definitions/classification-occupation/#elementor-toc__heading-anchor-2 for details.↩︎"
  },
  {
    "objectID": "posts/compa_countries/index.html",
    "href": "posts/compa_countries/index.html",
    "title": "Comparing countries with macro-level data",
    "section": "",
    "text": "Many important questions that political scientists, sociologists, or economists are asking are about patterns at the macro- or country-level: Why do some countries have bigger welfare states than others (Esping-Andersen 1990; Allan and Scruggs 2004; Korpi and Palme 2003; Iversen and Soskice 2006) or how do the political structures of a country affect its economic or environmental performance (Roller 2005; Acemoglu, Johnson, and Robinson 2001; Scruggs 2003)? Answering these questions usually requires some form of cross-country comparison with macro-level data on the size and shape of welfare states, political institutions, environmental performance, or economic growth. This analysis can be quantitative — also known as a time series cross-sectional regression analysis (see e.g., Beck 2001) — but it can also be a qualitative comparative case study — and even in the latter case, a few nice graphs that show relevant developments, patterns, and trends at the country-level can make the case study much more convincing and easy to follow.\nLuckily, we are now sitting on a mountain of (usually) freely available macro-level data on all kinds of economic, social, political, or environmental aspects for many countries and over long periods of time. To name just a few examples:\n\nInternational institutions such as the World Bank, the OECD, the European Union, or the UN offer free data on a vast number of economic, social, environmental, and political variables for their member countries.\nThe V-DEM project provides very detailed data on how democratic countries are for many countries going back to the 17-hundreds.\nThere are also many different datasets that measure countries’ political institutions, constitutional structures, party systems, election outcomes, and the representation of parties in parliaments and governments (see the Dataset of Political Datasets.)\nResearchers in international relations and peace & conflict studies have created many datasets on countries’ military strengths, alliances, conflicts, wars, terrorist attacks, and many other aspects (see https://github.com/erikgahner/PolData?tab=readme-ov-file#international-relations.)\n\nIn addition, many datasets come with associated R packages that allow you do directly import the datasets (see e.g., the vdemdata, WDI, or manifestoR packages).\nThere are different ways to work with macro-level data. A beginner-friendly way to work with macro-level data is to do descriptive analyses, and that is what the rest of this post is going to focus on.\nMore specifically, we will go over some example techniques using the Comparative Political Data Set (CPDS; https://cpds-data.org/), which is a very popular and fairly easy-to-work-with dataset in political science. It is a kind of Swiss army knife of macro-level data that includes the (usually) most relevant political, economic, and social macro-level indicators for a set of wealthy democracies in Europe, North America, and Australasia for the post-World War II period in one single source (e.g., GDP growth, the partisan composition of parliaments and governments, welfare state spending, or political institutions)."
  },
  {
    "objectID": "posts/compa_countries/index.html#why-we-do-macro-level-comparisons",
    "href": "posts/compa_countries/index.html#why-we-do-macro-level-comparisons",
    "title": "Comparing countries with macro-level data",
    "section": "",
    "text": "Many important questions that political scientists, sociologists, or economists are asking are about patterns at the macro- or country-level: Why do some countries have bigger welfare states than others (Esping-Andersen 1990; Allan and Scruggs 2004; Korpi and Palme 2003; Iversen and Soskice 2006) or how do the political structures of a country affect its economic or environmental performance (Roller 2005; Acemoglu, Johnson, and Robinson 2001; Scruggs 2003)? Answering these questions usually requires some form of cross-country comparison with macro-level data on the size and shape of welfare states, political institutions, environmental performance, or economic growth. This analysis can be quantitative — also known as a time series cross-sectional regression analysis (see e.g., Beck 2001) — but it can also be a qualitative comparative case study — and even in the latter case, a few nice graphs that show relevant developments, patterns, and trends at the country-level can make the case study much more convincing and easy to follow.\nLuckily, we are now sitting on a mountain of (usually) freely available macro-level data on all kinds of economic, social, political, or environmental aspects for many countries and over long periods of time. To name just a few examples:\n\nInternational institutions such as the World Bank, the OECD, the European Union, or the UN offer free data on a vast number of economic, social, environmental, and political variables for their member countries.\nThe V-DEM project provides very detailed data on how democratic countries are for many countries going back to the 17-hundreds.\nThere are also many different datasets that measure countries’ political institutions, constitutional structures, party systems, election outcomes, and the representation of parties in parliaments and governments (see the Dataset of Political Datasets.)\nResearchers in international relations and peace & conflict studies have created many datasets on countries’ military strengths, alliances, conflicts, wars, terrorist attacks, and many other aspects (see https://github.com/erikgahner/PolData?tab=readme-ov-file#international-relations.)\n\nIn addition, many datasets come with associated R packages that allow you do directly import the datasets (see e.g., the vdemdata, WDI, or manifestoR packages).\nThere are different ways to work with macro-level data. A beginner-friendly way to work with macro-level data is to do descriptive analyses, and that is what the rest of this post is going to focus on.\nMore specifically, we will go over some example techniques using the Comparative Political Data Set (CPDS; https://cpds-data.org/), which is a very popular and fairly easy-to-work-with dataset in political science. It is a kind of Swiss army knife of macro-level data that includes the (usually) most relevant political, economic, and social macro-level indicators for a set of wealthy democracies in Europe, North America, and Australasia for the post-World War II period in one single source (e.g., GDP growth, the partisan composition of parliaments and governments, welfare state spending, or political institutions)."
  },
  {
    "objectID": "posts/compa_countries/index.html#setup",
    "href": "posts/compa_countries/index.html#setup",
    "title": "Comparing countries with macro-level data",
    "section": "Setup",
    "text": "Setup\nIf you want to follow along, make sure you have the tidyverse loaded and, if you like, pre-set the ggplot2 graph theme to save time later:\n\nlibrary(tidyverse)\ntheme_set(theme_classic())"
  },
  {
    "objectID": "posts/compa_countries/index.html#what-macro-level-data-should-look-like",
    "href": "posts/compa_countries/index.html#what-macro-level-data-should-look-like",
    "title": "Comparing countries with macro-level data",
    "section": "What macro-level data (should) look like",
    "text": "What macro-level data (should) look like\nThe first important thing to understand is how a macro-level dataset should look like if you want to analyze it in R. As per Hadley Wickham’s Rules for Tidy Data (2014), all datasets should be structured in a way that:\n\nEvery row is an observation\nEvery column is a variable\n\nThis is easy when we work with a typical micro-level survey dataset like the European Social Survey, where the unit of observation is a single person. Here, every person is a row and every aspect that is recorded about them (their gender, income, age, etc.) is a column.\nIn a typical macro-level dataset, the unit of observation is usually a country-year: We observe Norway in 1990, 1991, 1992, and so on, and then we observe the France, Sweden, Japan, etc. in the same years.1 Here is a simple example of how this should look like using data on GDP growth (realgdpgr) from the CPDS dataset:\n\n\n\n\n\n\nImportant\n\n\n\nThis is how your dataset should look like!\n\n\n\n\n# A tibble: 12 × 4\n    year country iso   realgdpgr\n   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;\n 1  1990 France  FRA       3.03 \n 2  1991 France  FRA       0.944\n 3  1992 France  FRA       1.48 \n 4  1990 Japan   JPN       5.57 \n 5  1991 Japan   JPN       3.32 \n 6  1992 Japan   JPN       0.819\n 7  1990 Norway  NOR       1.93 \n 8  1991 Norway  NOR       3.08 \n 9  1992 Norway  NOR       3.57 \n10  1990 Sweden  SWE       0.755\n11  1991 Sweden  SWE      -1.15 \n12  1992 Sweden  SWE      -1.16 \n\n\nYou see that the individual observations for each country and year (country-years) are “stacked” on top of each other, and that we have two variables, country and year telling us which year and which country a given row corresponds to. These are important: You absolutely need to keep these variables in your dataset, otherwise you no longer know what each row in your dataset corresponds to. In addition, it is important to be aware that country and year in combination identify each unique observation: There is one “Norway in 1990”, one “Norway in 1991”, etc. observation, and you need to have both the country and the year variable to identify these observations.\nThe table also shows countries in two different formats: The plain English name, and the three-digit ISO country code. Many datasets use either of them (or different country codes), which can sometimes be a hassle to work with. Luckily, there is the countrycode package, which allows you to convert different country codes and names to other formats with a few lines of code.\nSometimes, and this can happen often when you download data from international organizations, the data you get look different (e.g., each row corresponds to a country and the columns refer to variables and years):\n\n\n\n\n\n\nImportant\n\n\n\nThis is how your dataset should not look like!\n\n\n\n\n# A tibble: 4 × 4\n  country realgdpgr_1990 realgdpgr_1991 realgdpgr_1992\n  &lt;chr&gt;            &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1 France           3.03           0.944          1.48 \n2 Japan            5.57           3.32           0.819\n3 Norway           1.93           3.08           3.57 \n4 Sweden           0.755         -1.15          -1.16 \n\n\nIf you do have a dataset that looks like this, you need to learn how to pivot or reshape your dataset. Here, the pivot_longer() and pivot_wider() functions from the tidyr package (included in the tidyverse) are your best friends (see also Urdinez and Cruz 2020, chap. 2.5.1)."
  },
  {
    "objectID": "posts/compa_countries/index.html#importing-the-cpds-dataset",
    "href": "posts/compa_countries/index.html#importing-the-cpds-dataset",
    "title": "Comparing countries with macro-level data",
    "section": "Importing the CPDS dataset",
    "text": "Importing the CPDS dataset\nOK, enough theory — time to work with some data. If you want to follow along, you need to download the latest version of the CPDS dataset (https://cpds-data.org/data/). Ideally, download the Stata version, unzip the file, and store it in your RStudio project folder (or the folder that is your current Working Directory, which you can find out with the getwd() function). Once you have that, all you need to do is to use the haven package to import the dataset:\n\ncpds &lt;- haven::read_dta(\"CPDS_1960_2022_Update_2024.dta\")\n\nThe cpds object should now pop up in your Environment tab in RStudio. If you like, you can take a brief look at the data with glimpse. You should also download the official codebook and get familiar with the variables that are included in the dataset!\nAnother way to get a sense of what is contained is to look at the unique countries and years that are covered:\n\nunique(cpds$year)\n\n [1] 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974\n[16] 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989\n[31] 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004\n[46] 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019\n[61] 2020 2021 2022\n\nunique(cpds$country)\n\n [1] \"Australia\"      \"Austria\"        \"Belgium\"        \"Bulgaria\"      \n [5] \"Canada\"         \"Croatia\"        \"Cyprus\"         \"Czech Republic\"\n [9] \"Denmark\"        \"Estonia\"        \"Finland\"        \"France\"        \n[13] \"Germany\"        \"Greece\"         \"Hungary\"        \"Iceland\"       \n[17] \"Ireland\"        \"Italy\"          \"Japan\"          \"Latvia\"        \n[21] \"Lithuania\"      \"Luxembourg\"     \"Malta\"          \"Netherlands\"   \n[25] \"New Zealand\"    \"Norway\"         \"Poland\"         \"Portugal\"      \n[29] \"Romania\"        \"Slovakia\"       \"Slovenia\"       \"Spain\"         \n[33] \"Sweden\"         \"Switzerland\"    \"United Kingdom\" \"USA\"           \n\n\nYou see that we have, in principle, data for almost all of Europe and the other advanced democracies around the globe from the 1960s onwards. What this does not show, however, is that we only have data for the Central and Eastern European countries (Poland, Bulgaria, etc.) from 1990 on, after the collapse of the Soviet Union and the Warsaw Pact:\n\ncpds |&gt; \n  filter(country == \"Poland\") |&gt; \n  select(year,country)\n\n# A tibble: 32 × 2\n    year country\n   &lt;dbl&gt; &lt;chr&gt;  \n 1  1991 Poland \n 2  1992 Poland \n 3  1993 Poland \n 4  1994 Poland \n 5  1995 Poland \n 6  1996 Poland \n 7  1997 Poland \n 8  1998 Poland \n 9  1999 Poland \n10  2000 Poland \n# ℹ 22 more rows\n\n\nBecause such a large batch of countries was added at this one time point, it makes sense to limit the data to the post-1990 period — otherwise, comparisons over time might not make sense.\n\ncpds |&gt; \n  filter(year&gt;=1990) -&gt; cpds\n\n(An alternative, if the interest is in long trends since World War II, is to leave out the post-communist countries. Here, the poco — “post-communist” — variable in the CPDS dataset is useful within filter().)"
  },
  {
    "objectID": "posts/compa_countries/index.html#descriptive-analyses-with-macro-level-data",
    "href": "posts/compa_countries/index.html#descriptive-analyses-with-macro-level-data",
    "title": "Comparing countries with macro-level data",
    "section": "Descriptive analyses with macro-level data",
    "text": "Descriptive analyses with macro-level data\nThere are four basic ways to look descriptively at macro-level data:\n\nYou can look at general trends across countries over time\nYou can compare average patterns between countries\nYou can compare trends within selected countries over time\nYou can look at average relationships (correlations) between countries\n\nEach of them tells you a different part of the entire story that is contained in the data. We will go over each of them and see how to aggregate and visualize the data. In most cases, your two best friends are the group_by() and summarize() functions from dplyr.\n\nAggregating by year to show general trends\nSometimes, we want to show to our readers general trends that existed more or less in all countries in the dataset over a given period of time. For example, we might want to show general phases of economic boom and crisis that affected all the advanced democracies, without looking specifically at individual countries. To do that, we can calculate the average rate of economic growth over all countries per year and visualize the result.\nThis is easy to do with group_by() and summarize():\n\ncpds |&gt; \n  group_by(year) |&gt; \n  summarize(avg_growth = mean(realgdpgr, na.rm = T))\n\n# A tibble: 33 × 2\n    year avg_growth\n   &lt;dbl&gt;      &lt;dbl&gt;\n 1  1990      2.76 \n 2  1991     -0.473\n 3  1992     -0.372\n 4  1993      0.124\n 5  1994      3.14 \n 6  1995      3.56 \n 7  1996      3.23 \n 8  1997      3.81 \n 9  1998      3.78 \n10  1999      2.94 \n# ℹ 23 more rows\n\n\nHere, we group the data by year and then calculate for each year the average of all GPD growth rates in all of the countries that are covered in the dataset. The result is an aggregated version of the dataset with average rates of GPD growth per year since the 1960s as individual observations.2\nWe can then visualize the result in a line graph:\n\ncpds |&gt; \n  group_by(year) |&gt; \n  summarize(avg_growth = mean(realgdpgr, na.rm = T)) |&gt; \n  ggplot(aes(x = year, y = avg_growth)) +\n    geom_line() +\n    geom_point() +\n    geom_hline(yintercept = 0, \n               linetype = \"dashed\", color = \"grey\") +\n    labs(x = \"\", y = \"Average GDP growth rate\") +\n    scale_x_continuous(breaks = seq(1960,2020,10))\n\n\n\n\n\n\n\n\nThe graph clearly shows the last two big economic crises, the 2008 Financial Crisis (a.k.a., Great Recession) and the COVID-19 pandemic, but also the economic crisis of the early 1990s.\n\n\n\n\n\n\nImportant\n\n\n\nYou may notice that we do not save the resulting aggregated dataset in a separate object — and we most definitely do not overwrite the original dataset with the aggregated version. We simply aggregate the data “on the fly”, visualize the result, and then let the aggregated version disappear into the ether. Sometimes, you might want to save an aggregated dataset so that you can use it in later analyses, but in that case you need to make sure that you give it a different name.\n\n\nIt is also important to be aware that we can also calculate other types of summary statistics like the median, the variance, or the standard deviation within summarize(). The latter is very helpful if we want to show not only average trends but also the variation around the trend line. To do that, we simply add the summary statistic we want within summarize():\n\ncpds |&gt; \n  group_by(year) |&gt; \n  summarise(avg_growth = mean(realgdpgr, na.rm = T),\n            sd_growth = sd(realgdpgr, na.rm = T))\n\n# A tibble: 33 × 3\n    year avg_growth sd_growth\n   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n 1  1990      2.76       2.17\n 2  1991     -0.473      5.21\n 3  1992     -0.372      5.28\n 4  1993      0.124      4.14\n 5  1994      3.14       2.93\n 6  1995      3.56       2.29\n 7  1996      3.23       1.75\n 8  1997      3.81       4.40\n 9  1998      3.78       2.33\n10  1999      2.94       3.05\n# ℹ 23 more rows\n\n\nNow we get two summary statistics per year: The average growth rates and the standard deviation in growth rates (the average deviation from the average). To visualize this, we can calculate +/- 1 standard deviation ranges around the mean values and use geom_ribbon() in ggplot() to visualize the result:\n\ncpds |&gt; \n  group_by(year) |&gt; \n  summarise(avg_growth = mean(realgdpgr, na.rm = T),\n            sd_growth = sd(realgdpgr, na.rm = T)) |&gt; \n  mutate(upper = avg_growth + sd_growth,\n         lower = avg_growth - sd_growth) |&gt; \n  ggplot(aes(x = year, y = avg_growth, ymin = lower, ymax = upper)) +\n    geom_line() +\n    geom_point() +\n    geom_ribbon(alpha = .2) + # alpha makes the area transparent\n    geom_hline(yintercept = 0, \n               linetype = \"dashed\", color = \"black\") +\n    labs(x = \"\", y = \"Average GDP growth rate\",\n         caption = \"Shaded area indicates +/- 1 SD ranges.\") +\n    scale_x_continuous(breaks = seq(1960,2020,10))\n\n\n\n\n\n\n\n\nOne new lesson we learn is that although the average growth rate dipped into the negative in the early 1990s, there was also increased variation in growth rates — the range got visibly bigger — which indicates that not all countries were equally strongly affected by the crisis.\n\n\nAggregating by country to show differences\nAnother thing we might be interested in is which countries had, on average, the highest or lowest growth rates in the period between 1990 and today. To see this, we again use group_by() and summarize(), but we now group by country instead of year:\n\ncpds |&gt; \n  group_by(country) |&gt; \n  summarise(avg_growth = mean(realgdpgr, na.rm = T))\n\n# A tibble: 36 × 2\n   country        avg_growth\n   &lt;chr&gt;               &lt;dbl&gt;\n 1 Australia            2.89\n 2 Austria              1.87\n 3 Belgium              1.81\n 4 Bulgaria             1.94\n 5 Canada               2.13\n 6 Croatia              2.34\n 7 Cyprus               3.41\n 8 Czech Republic       1.58\n 9 Denmark              1.76\n10 Estonia              4.02\n# ℹ 26 more rows\n\n\nAs before, we now get an aggregated version of the dataset — but now it is aggregated by country, not by year. We see that for example Australia had an average growth rate of arond 3.3% per year, while the rate in the Czech Republic was only around 1.6% per year.\nWe can again visualize the result, but here a bar graph makes most sense. We can also use reorder() to sort the bars according to the average growth rate:\n\ncpds |&gt; \n  group_by(country) |&gt; \n  summarise(avg_growth = mean(realgdpgr, na.rm = T)) |&gt; \n  ggplot(aes(x = avg_growth, y = reorder(country, avg_growth))) +\n    geom_col() +\n    labs(x = \"Average rate of GDP growth (%)\", y = \"\")\n\n\n\n\n\n\n\n\nYou see that Ireland (the Irish Tiger) had by far the highest growth rate since the 1990s, followed by Malta and Estonia. Italy, Greece, and Japan had clearly the lowest average rates of growth.\n\n\nComparing selected countries over time\nSometimes, for example when you do a comparative case study of a few selected countries, you want to show relevant developments in those countries, without any aggregation. This is obviously also possible with this type of data, and here the filter() function is your best friend.\nLet’s say we want to compare the development of economic growth rates in the four largest Nordic countries (Denmark, Finland, Norway, Sweden) since the 1990s. In that case, we just need to use filter() to subset the data to those countries:\n\ncpds |&gt; \n  select(country,year,realgdpgr) |&gt; # this is technically not necessary, but \n  # sometimes useful to avoid losing overview over the data\n  filter(country %in% c(\"Denmark\",\"Finland\",\"Sweden\",\"Norway\"))\n\n# A tibble: 132 × 3\n   country  year realgdpgr\n   &lt;chr&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n 1 Denmark  1990    1.48  \n 2 Denmark  1991    1.39  \n 3 Denmark  1992    1.96  \n 4 Denmark  1993    0.0107\n 5 Denmark  1994    5.33  \n 6 Denmark  1995    3.03  \n 7 Denmark  1996    2.90  \n 8 Denmark  1997    3.26  \n 9 Denmark  1998    2.21  \n10 Denmark  1999    2.95  \n# ℹ 122 more rows\n\n\nThis is all there is to it — we now have limited the dataset to the four Nordic countries. Obviously, the result is not very informative, but we can again visualize the result in a line graph with ggplot():\n\ncpds |&gt; \n  select(country,year,realgdpgr) |&gt; # this is technically not necessary, but \n  # sometimes useful to avoid losing overview over the data\n  filter(country %in% c(\"Denmark\",\"Finland\",\"Sweden\",\"Norway\")) |&gt; \n  ggplot(aes(x = year, y = realgdpgr, group = country, color = country)) +\n    geom_line(linewidth = 1) +\n    geom_hline(yintercept = 0, linetype = \"dashed\", color = \"grey\") +\n    scale_color_brewer(palette = \"Paired\") + # color-blind friendly palette\n    scale_x_continuous(breaks = seq(1990,2020,5)) +\n    labs(y = \"GDP growth rate (%)\", x = \"\", color = \"\") +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nIn general, growth rates in the four countries are (unsurprisingly) behaving quite similarly — when Denmark experiences a crisis, Sweden, Norway, and Finland do as well — but it does seem that Finland tends a bit more toward the extremes than the other countries. Crises tend to hit hardest in Finland, but the following recoveries are also stronger.\nAn alternative way to visualize the result is to use facet_wrap() to create a separate graph for each country. This helps if, as is the case here, the lines overlap strongly:\n\ncpds |&gt; \n  filter(country %in% c(\"Denmark\",\"Finland\",\"Sweden\",\"Norway\")) |&gt; \n  ggplot(aes(x = year, y = realgdpgr)) +\n    geom_line() +\n    geom_hline(yintercept = 0, linetype = \"dashed\", color = \"grey\") +\n    facet_wrap(~ country) +\n    scale_x_continuous(breaks = seq(1990,2020,5)) +\n    labs(y = \"GDP growth rate (%)\", x = \"\", color = \"\") +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nThe more extreme up- and downswings in Finland are still visible.\n\n\nShowing bivariate relationships across countries\nAlthough the development of a single variable over time or its variation between countries is often relevant to look at, we are in most cases primarily interested in relationships between variables: Does one variable affect the other, or are they at least correlated with each other?\nOne wat to check for bivariate relationships between two variables is to aggregate both variables by country and then use a scatterplot to visualize the result.\nLet’s say we wanted to test the hypothesis that a stronger presence of left parties in government is bad for economic growth (as some people claim). The gov_left1 variable from the CDPS dataset gives us the share of cabinet posts that are held by left-of-center parties in a given year and country, and we can simply aggregate this variable along with the one measuring economic growth within summarize():\n\ncpds |&gt; \n  group_by(country) |&gt; \n  summarise(avg_growth = mean(realgdpgr, na.rm = T),\n            avg_leftgov = mean(gov_left1, na.rm = T)) \n\n# A tibble: 36 × 3\n   country        avg_growth avg_leftgov\n   &lt;chr&gt;               &lt;dbl&gt;       &lt;dbl&gt;\n 1 Australia            2.89        38.1\n 2 Austria              1.87        33.8\n 3 Belgium              1.81        38.2\n 4 Bulgaria             1.94        16.2\n 5 Canada               2.13         0  \n 6 Croatia              2.34        20.7\n 7 Cyprus               3.41        13.8\n 8 Czech Republic       1.58        28.3\n 9 Denmark              1.76        38.8\n10 Estonia              4.02        21.7\n# ℹ 26 more rows\n\n\nThe numbers give us the average growth rate and the average share of cabinet posts held by left parties in each country in the period since 1990. We can now use geom_point() to visualize the result in a scatterplot, and add geom_smooth() to get a fitted line that highlights the relationship between the variables:\n\ncpds |&gt; \n  group_by(country) |&gt; \n  summarise(avg_growth = mean(realgdpgr, na.rm = T),\n            avg_leftgov = mean(gov_left1, na.rm = T)) |&gt; \n  ggplot(aes(x = avg_leftgov, y = avg_growth)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = F, color = \"grey\", \n                linetype = \"dashed\") +\n    labs(x = \"Avg. share of left parties in government (%)\",\n         y = \"Average rate of economic growth (%)\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThere is indeed a negative — but quite weak — relationship between the two variables. However, it important not to forget that the arrow of causality might run the other way: Maybe left parties get elected more often in times of economic crises? (What happens when you look at the relationship between economic growth and the share of right parties in government using gov_right1?)\nOne way to still improve the graph is to add labels for each country instead of anonymous black dots to be able to see where the different countries are located. To do that, we can replace geom_point() with geom_text(), and we use the iso variable (which is equivalent to the country variable) to aggregate the data. By using iso, we later have handy short labels that we can use in the graph:\n\ncpds |&gt; \n  group_by(iso) |&gt; \n  summarise(avg_growth = mean(realgdpgr, na.rm = T),\n            avg_leftgov = mean(gov_left1, na.rm = T)) |&gt; \n  ggplot(aes(x = avg_leftgov, y = avg_growth)) +\n    geom_text(aes(label = iso)) +\n    geom_smooth(method = \"lm\", se = F, color = \"grey\", \n                linetype = \"dashed\") +\n    labs(x = \"Avg. share of left parties in government (%)\",\n         y = \"Average rate of economic growth (%)\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThis clarifies matters. It almost seems as if the slight negative relationship between left government participation and economic growth is mainly driven by the outlying case of Ireland…"
  },
  {
    "objectID": "posts/compa_countries/index.html#what-next",
    "href": "posts/compa_countries/index.html#what-next",
    "title": "Comparing countries with macro-level data",
    "section": "What next?",
    "text": "What next?\nThis post showed you how you can do descriptive analyses of cross-country macro-level (or time series cross-sectional) datasets. This can help you spice up a comparative case study with descriptive statistics of relevant macro-level indicators, and it can be a stepping stone toward learning how to do regression analyses with this type of data.\nMore concrete steps you can take to advance further are:\n\nGet more of an overview over what macro-level datasets there are out there (see also the sources above).\nLearn how to combine (“merge”) different datasets. This is not as difficult as it might sound. Since all these datasets have the same underlying country-year structure, you just need to figure out how to work with the left_join() function to merge datasets (see also the post on how to measure globalization exposure), and probably also how to convert different country codes and names between each other with the countrycode package (see also Urdinez and Cruz 2020, chap. 11).\nExplore other types of macro-level datasets. Relevant examples are the Manifesto Project Database, which provides quantitative estimates of the ideological positions of political parties in different countries (here, the unit of observation is a party at a given election or “party-election”) or different peace & conflict datasets (e.g., Raleigh et al. 2010; Uppsala Conflict Data Program 2014; Gibler and Miller 2023; Vogt et al. 2015).\nLearn how to do multivariate regression analyses with these datasets. Relevant works to read are Beck and Katz (1995, 1996, 2011), Beck, Katz, and Tucker (1998), Beck (2001), De Boef and Keele (2008), Wilson and Butler (2007), Carter and Signorino (2010), Honaker and King (2010), Birkel (2014), and for more advanced methods see Blackwell and Glynn (2018). Urdinez and Cruz (2020, chap. 7) and Croissant and Millo (2008) show how to implement the main techniques in R."
  },
  {
    "objectID": "posts/compa_countries/index.html#footnotes",
    "href": "posts/compa_countries/index.html#footnotes",
    "title": "Comparing countries with macro-level data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAn exception are many peace & conflict datasets, where the unit of observation is a country-pair (dyad) or a conflict-year. This can make these datasets a bit more difficult to work with.↩︎\nObviously, you should always make sure that you do not have large changes in the composition of your dataset — e.g., where many new countries are added from a given year on — because that can lead to sudden jumps or dips in the average values.↩︎"
  },
  {
    "objectID": "posts/datasources/index.html",
    "href": "posts/datasources/index.html",
    "title": "‘I can’t find any data!’",
    "section": "",
    "text": "Finding relevant data is one of the major hurdles students face during term paper or thesis projects — which is a bit puzzling given that there is a huge and growing amount of data about many political, social, or economic aspects freely available on the open internet.\nThis post provides a (definitely not exhaustive) list of datasets and data repositories that can be relevant for research projects in the social and political sciences. It is not the first such list (see below), but it complements other lists with a stronger focus on datasets from and relevant for research on welfare states.\nLinks to most data sources are provided, those without links should be easy to find. The list and links are updated every once in a while."
  },
  {
    "objectID": "posts/datasources/index.html#forests-and-trees",
    "href": "posts/datasources/index.html#forests-and-trees",
    "title": "‘I can’t find any data!’",
    "section": "",
    "text": "Finding relevant data is one of the major hurdles students face during term paper or thesis projects — which is a bit puzzling given that there is a huge and growing amount of data about many political, social, or economic aspects freely available on the open internet.\nThis post provides a (definitely not exhaustive) list of datasets and data repositories that can be relevant for research projects in the social and political sciences. It is not the first such list (see below), but it complements other lists with a stronger focus on datasets from and relevant for research on welfare states.\nLinks to most data sources are provided, those without links should be easy to find. The list and links are updated every once in a while."
  },
  {
    "objectID": "posts/datasources/index.html#other-better-overviews-over-available-data",
    "href": "posts/datasources/index.html#other-better-overviews-over-available-data",
    "title": "‘I can’t find any data!’",
    "section": "Other (better?) overviews over available data",
    "text": "Other (better?) overviews over available data\nErik Gahner’s excellent Dataset of Political Datasets provides a great overview over datasets that are relevant for political science research, and there are also a number of data repositories and archives that contain even more (and partly older) data that might be relevant for some projects, for example:\n\nThe GESIS survey data repository for survey data\nThe Norwegian Norsk senter for forskningsdata (NSD) or Datafabrikken."
  },
  {
    "objectID": "posts/datasources/index.html#survey-data",
    "href": "posts/datasources/index.html#survey-data",
    "title": "‘I can’t find any data!’",
    "section": "Survey data",
    "text": "Survey data\n\nGeneral social survey data\n\nEuropean Social Survey (ESS): https://europeansocialsurvey.org/\nInternational Social Survey Program (ISSP): https://issp.org/\nEurobarometer: Public attitudes toward large range of topics; see https://www.gesis.org/en/eurobarometer-data-service/search-data-access/topics\nArab Barometer: Public opinion data from MENA countries (https://www.arabbarometer.org/)\nWorld Values Survey (WVS)\nUS General Social Survey (GSS)\nPEW polling data (partly avaiable for free, after registration): https://www.pewresearch.org/tools-and-resources/1\n\n\n\nElection/voter survey data\n\nComparative Study of Electoral Systems (http://www.cses.org/): Standardized election surveys from several countries and elections\nAmerican National Election Study (http://www.electionstudies.org/)\nNorwegian National Election Study/Norsk Valgundersøkelser (available via NSD; see above)\nUS VOTER survey data: Unique longitudinal survey data allowing for deep exploration of public opinion on the issues and values that drive voter behavior.\n\n\n\nSocietal safety & crisis preparedness\n\nUS Federal Emergency Management Agency (FEMA) National Household Survey: Representative survey data on the American public’s preparedness actions, attitudes, and motivations.\nSeveral Special Eurobarometer surveys from different years look at attitudes toward disaster prevention and civil protection: See https://europa.eu/eurobarometer/surveys/browse/all; search in Keywords for “Civil protection”; access data via GESIS’ ZACAT Data Archive (see above)\nThe 2016 round of the International Social Survey Program (https://www.gesis.org/en/issp/modules/issp-modules-by-topic/role-of-government/2016) included questions on attitudes toward national security and anti-terror measures such as video surveillance or detention of terrorist suspects.\n\n\n\nOther\n\nThe Public Opinion Quarterly provides reviews of recent polling data on specific topics (e.g., De Boer 1983); search for “The Polls” or “Poll Reviews”\nEurostat Survey Data: Includes e.g. the European Labour Force Survey (ELFS), European Community Household Panel (ECHP), European Union Statistics on Income and Living Conditions (EU-SILC),…}\nSurvey of Health, Ageing and Retirement in Europe (SHARE)\nEvidence for Equality National Survey (EVENS): Survey data on the experiences of ethnic minorities in the UK during the COVID-19 pandemic (see also Finney et al. 2023)\nVarious national & international panel surveys (German SOEP, British BHPS, Swiss SHP, Swedish LNU, U.S. PSID, Japanese JHPS,…)"
  },
  {
    "objectID": "posts/datasources/index.html#cross-national-comparative-data",
    "href": "posts/datasources/index.html#cross-national-comparative-data",
    "title": "‘I can’t find any data!’",
    "section": "Cross-national comparative data",
    "text": "Cross-national comparative data\n\nInternational organizations\n\nOECD: https://www.oecd.org/en/data.html\nWorld Bank: https://data.worldbank.org/\nIMF: https://www.imf.org/en/Data\nILO: https://ilostat.ilo.org/\nEurostat: https://ec.europa.eu/eurostat\nUN: https://data.un.org/\nUNESCO: https://databrowser.uis.unesco.org/\nUNHCR: https://www.unhcr.org/what-we-do/reports-and-publications/unhcr-data\nWHO: https://data.wto.org/en\n\n\n\nComparative politics: Governments, parliaments, parties, institutions, elections\n\nManifesto Project Database: Ideological positions of political parties (https://manifestoproject.wzb.eu/)\nIntegrated Party Organization Dataset (http://dx.doi.org/10.7910/DVN/PE8TWP)\nPARTY FACTS: Repository of comparative and historical data on political parties in around 200 countries (https://partyfacts.herokuapp.com/)\nParliament and government composition (PARLGOV; https://www.parlgov.org/) database\nInter-Parliamentary Union: Qualitative descriptions of parliaments and electoral systems, and key statistics on the composition of parliaments in most countries of the world (https://www.ipu.org/)\nPOLCON: Index of political constraints (“checks & balances”), information about heads of states, governments, government parties (https://mgmt.wharton.upenn.edu/faculty/heniszpolcon/polcondataset/)\nVarieties of Democracy (V-DEM): Indicators of democracy, very detailed and for 177 countries between 1900 and today (https://www.v-dem.net/)\nExecutive Approval Project: Cross-country comparative data on public support for political executives (http://www.executiveapproval.org/)\nDemocratic Electoral Systems Around the World, 1946-2011 (see also Golder 2005; Bormann and Golder 2013)\nEuropean Journal of Political Research Political Data Yearbook: Qualitative info on elections, government composition, important issues in national politics (http://onlinelibrary.wiley.com/journal/10.1111/%28ISSN%292047-8852)\nInternational Institute for Democracy and Electoral Assistance (IDEA): Comparative (often qualitative) data on electoral systems, campaign finance rules, direct democracy, gender quotas, voter turnout,… (https://www.idea.int/)\nGlobal Leadership Project (GLP): Data on government leaders throughout the world - including legislators, members of the executive branch, members of the judiciary, and other decisionmakers whose power may be formal or informal (https://globalleadershipproject.net/)\nCline Center Historical Phoenix Event Data: Machine-generated data on historical events between 1945 and 2015 extracted from 14 million news stories. It documents the agents, locations, and issues at stake in a wide variety of conflict, cooperation and communicative events.\nThe Electoral Integrity Project: Data from expert surveys on the integrity of elections in countries around the globe (https://www.electoralintegrityproject.com/)\nPPEG Database on political parties, presidents, elections, and governments around the world (https://ppeg.wzb.eu/)\nCongress in Data: Information about the characteristics of US Congress Members, their legislative activities, and their social connections over five US Congress cycles: from the 109th to the 113th (2005-2015)\nComparative Legislators Database (CLD)}: Rich, diverse and integrated individual-level data on national political representatives. The database contains information for over 67,000 contemporary and historical legislators from 16 countries (see also Göbel and Munzert 2022)\nWhoGov: Information (e.g., gender, party affiliation) on cabinet members in July every year in the period 1966-2021 in all countries with a population of more than 400,000 citizens (see also Nyrup and Bramwell 2020)\nParliaments Day-By-Day: Open-source data on MPs’ membership in parties, parliaments, and party groups (see also Turner-Zwinkels et al. 2022)\n\n\n\nWelfare state, social inequality, & social policies\n\nThe Social Policy Indicators (SPIN) database\nGlobal Welfare State Information System (WeSIS): comprehensive data to describe and explain social policy worldwide\nWorld Inequality Database (WID): global database on the distribution of wealth and income (see also Piketty 2014)\nComparative Welfare Entitlements Project (CWEP): Comparative data on pension, unemployment, and sickness insurance generosity\nMoira Nelson’s and my comparative Unemployment Benefit Conditionality Dataset: Comparative data on job-search requirements, the definition of suitable work, and sanctions for unemployment benefit claimants in 21 OECD countries between 1980 and 2012. See also the OECD’s dataset on benefit eligibility requirements for more recent data\nJohn Stephens & Evelyne Huber’s Comparative Welfare States & Social Policy in Latin America Datasets\nMISSOC: Qualitative information on social security and assistance schemes in EU countries (https://www.missoc.org/)\nOECD Benefits & Wages: Qualitative information on social security and social assistance schemes in OECD countries): Qualitative information on social security and social assistance schemes in OECD countries\nInternational Network on Leave Policies & Research: Qualitative reports on maternal, paternal, and parental leave schemes (https://www.leavenetwork.org/annual-review-reports/)\nEuropean Trade Union Institute (ETUI) Reforms Watch: Individual EU country dossiers with fact-based information on the state of labour market reforms, the state of pension reforms, developments in legislation on strikes and data on strike activities\nSocial Assistance in Developing Countries Database: Summary information on social assistance interventions in developing countries (https://www.social-protection.org/gimi/gess/ShowRessource.action?ressource.ressourceId=9491)\nGlobal Welfare (GLOW): The database includes 381 variables on 61 countries from years between 1989 and 2015. The database has four main categories of data: welfare, development, economy and politics\nEducation Policies and Systems across Modern History EPSM dataset: measures on compulsory education, ideological guidance and content of education, governmental intervention and level of education centralization, and teacher training covering 157 countries with populations exceeding 1 million people from 1789 to the present (see also Del Rı́o, Knutsen, and Lutscher 2024)\nGlobal Tax Expenditures Database GTED: Information on preferential tax treatments such as exemptions, deductions, credits, deferrals and reduced tax rates that are implemented by governments worldwide to promote different policy goals.\nBarro-Lee Educational Attainment data: Data on educational attainment per country across the world between 1950 and 2010 (see also Barro and Lee 2013)\nSee also Clasen and Siegel (2007), Clasen, Clegg, and Goerne (2016), and a special issue in the Journal of European Public Policy (Wenzelburger, Zohlnhöfer, and Wolf 2013; Danforth and Stephens 2013; Scruggs 2013) on the “dependent variable problem” in comparative social policy research\n\n\n\nImmigration & immigrant integration\n\nCitizenship rights of immigrants (see also Koopmans, Michalowski, and Waibel 2012)\nMigrant Integration Policy Index MIPEX\nMigration Data Portal: information on the degree of restrictiveness of immigration policies in 33 OECD countries for the period 1980–2010\nImmigration Policies in Comparison: Quantitative indices to measure immigration policies in all OECD countries and for the time period 1980-2010. See also Helbling (2013) and Helbling and Michalowski (2017)\nImmigration in Party Manifestos Dataset (https://manifesto-project.wzb.eu/information/documents/pimpo)\n\n\n\nTechnology & technological change\n\nOECD Risks that Matter surveys: Cross-country comparative survey data, incl. questions on perceived vulnerability to technological change (see e.g., Busemeyer et al. 2023)\nEU KLEMS: Economic dataset that includes data on ICT investment for many countries and years (used by e.g., Gallego, Kurer, and Schöll 2022)\nAI exposure indicators: Indicators measuring exposure to AI at the occupational, industry, and regional (for US) level; see Felten, Raj, and Seamans (2021) for details\nKnowledge Economy Index: An index that measures the degree to which countries have transitioned toward a knowledge-based economy. The index covers 22 economically advanced countries between 1995 and 2019 (see also Diessner et al. 2025).\n\n\n\nSocial media\n\nTweetsKB: A database of annotated tweets, containing data for nearly 3.0 billion tweets between February 2013 - August 2022. Metadata information about the tweets as well as extracted entities, sentiments, hashtags and user mentions are exposed in RDF using established RDF/S vocabularies (see also Fafalios et al. 2018)\nThe Twitter Parliamentarian Database: a database consisting of parliamentarian names, parties and twitter ids from the following countries: Austria, Belgium, France, Denmark, Spain, Finland, Germany, Greece, Italy, Malta, Poland, Netherlands, United Kingdom, Ireland, Sweden, New Zealand, Turkey, United States, Canada, Australia, Iceland, Norway, Switzerland, Luxembourg, Latvia and Slovenia. In addition, the database includes the European Parliament\n\n\n\nTrade unions & industrial relations\n\nDatabase on Institutional Characteristics of Trade Unions, Wage Setting, State Intervention and Social Pacts ICTWSS\nEuropean Works Councils Database: Information on works councils in European and multinational companies, on EU and national-level works council legislation, and on relevant court cases (EU and national level)\nEuropean Company Survey: Comparative survey on businesses in Europe (see also Lehr, Jansen, and Brandl 2023)\nEuropean Observatory of Working Life (EurWORK)"
  },
  {
    "objectID": "posts/datasources/index.html#footnotes",
    "href": "posts/datasources/index.html#footnotes",
    "title": "‘I can’t find any data!’",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee also https://www.pewresearch.org/short-reads/2021/10/22/how-to-access-pew-research-center-survey-data/ for more details.↩︎"
  },
  {
    "objectID": "posts/compa_survey/index.html",
    "href": "posts/compa_survey/index.html",
    "title": "Comparing people’s behavior and attitudes across countries",
    "section": "",
    "text": "How much are people’s opinions, behaviors, or perceptions affected by the environments (or “macro-level contexts”) they live in? Many sociologists argue that societal norms shape people’s behavior (e.g., that men do more of the housework in societies with egalitarian gender norms), and political scientists similarly suggest that political institutions influence political attitudes and behavior (e.g., that people participate more in elections in proportional or majoritarian electoral systems).\nTo test these types of theories, one needs to compare people’s opinions or behavior across contexts with different social norms, political institutions, or other macro-level factors that might have an influence on people. This is usually done with comparative survey data such as data from the European Social Survey, the International Social Survey Program, the Eurobarometer, the OECD Risks that Matter survey, or the World Values Study.1 The big advantage that comparative survey data offer is that they are standardized: The same survey with the exact same questions is conducted in multiple countries at the same time, so that people’s responses to the questions – i.e., their attitudes or behavior – can be directly compared.2 This means that one can use these survey data to find out for macro-level environmental factors influence (or at least are correlated with) people’s individual behaviors and attitudes.\nThis type of analysis can seem daunting to students but – as always in life – there are easier and more complicated ways of doing this. This post shows you how to do it in the easiest way possible, using R and techniques that undergraduate students usually learn in their introductory statistics courses: Descriptive statistics and linear regression models (taking inspiration from Blekesaune and Bjørkhaug 2021).\nSimply put (TL;DR), you pick a comparative survey dataset that contains relevant variables and covers countries that differ in relevant ways. For example, to study the effects of gender norms on the household division of work, you would find a survey dataset that contains questions about how much time people spend on housework and which covers countries with very egalitarian gender norms and countries with very inegalitarian gender norms. Then you pick one country that has, based on other studies or datasets, egalitarian norms and one that has very inegalitarian norms and you analyze how couples divide household chores between them (see e.g., Iversen and Rosenbluth 2006). Ideally, the countries you pick are otherwise as similar as possible so that you can be more sure that any differences you find are really the result of gender norms and not other factors (see e.g., Ringdal 2018, chap. 9; King, Keohane, and Verba 1994; Landman 2003, chaps. 2–3 for an explanation of good case selection strategies).\nThematically, we stick to the general topic of gender and gender differences, but we do not look at household work. Instead, we look at the political gender gap: How men and women differ in their political opinions (Inglehart and Norris 2000; Iversen and Rosenbluth 2010, 2006). More specifically, we do a simple re-test of the “household bargaining theory” of political gender differences by Iversen & Rosenbluth (2006, 2010)."
  },
  {
    "objectID": "posts/compa_survey/index.html#are-people-influenced-by-the-environments-they-live-in",
    "href": "posts/compa_survey/index.html#are-people-influenced-by-the-environments-they-live-in",
    "title": "Comparing people’s behavior and attitudes across countries",
    "section": "",
    "text": "How much are people’s opinions, behaviors, or perceptions affected by the environments (or “macro-level contexts”) they live in? Many sociologists argue that societal norms shape people’s behavior (e.g., that men do more of the housework in societies with egalitarian gender norms), and political scientists similarly suggest that political institutions influence political attitudes and behavior (e.g., that people participate more in elections in proportional or majoritarian electoral systems).\nTo test these types of theories, one needs to compare people’s opinions or behavior across contexts with different social norms, political institutions, or other macro-level factors that might have an influence on people. This is usually done with comparative survey data such as data from the European Social Survey, the International Social Survey Program, the Eurobarometer, the OECD Risks that Matter survey, or the World Values Study.1 The big advantage that comparative survey data offer is that they are standardized: The same survey with the exact same questions is conducted in multiple countries at the same time, so that people’s responses to the questions – i.e., their attitudes or behavior – can be directly compared.2 This means that one can use these survey data to find out for macro-level environmental factors influence (or at least are correlated with) people’s individual behaviors and attitudes.\nThis type of analysis can seem daunting to students but – as always in life – there are easier and more complicated ways of doing this. This post shows you how to do it in the easiest way possible, using R and techniques that undergraduate students usually learn in their introductory statistics courses: Descriptive statistics and linear regression models (taking inspiration from Blekesaune and Bjørkhaug 2021).\nSimply put (TL;DR), you pick a comparative survey dataset that contains relevant variables and covers countries that differ in relevant ways. For example, to study the effects of gender norms on the household division of work, you would find a survey dataset that contains questions about how much time people spend on housework and which covers countries with very egalitarian gender norms and countries with very inegalitarian gender norms. Then you pick one country that has, based on other studies or datasets, egalitarian norms and one that has very inegalitarian norms and you analyze how couples divide household chores between them (see e.g., Iversen and Rosenbluth 2006). Ideally, the countries you pick are otherwise as similar as possible so that you can be more sure that any differences you find are really the result of gender norms and not other factors (see e.g., Ringdal 2018, chap. 9; King, Keohane, and Verba 1994; Landman 2003, chaps. 2–3 for an explanation of good case selection strategies).\nThematically, we stick to the general topic of gender and gender differences, but we do not look at household work. Instead, we look at the political gender gap: How men and women differ in their political opinions (Inglehart and Norris 2000; Iversen and Rosenbluth 2010, 2006). More specifically, we do a simple re-test of the “household bargaining theory” of political gender differences by Iversen & Rosenbluth (2006, 2010)."
  },
  {
    "objectID": "posts/compa_survey/index.html#the-iversenrosenbluth-hypothesis-in-the-smallest-of-nutshells",
    "href": "posts/compa_survey/index.html#the-iversenrosenbluth-hypothesis-in-the-smallest-of-nutshells",
    "title": "Comparing people’s behavior and attitudes across countries",
    "section": "The Iversen/Rosenbluth hypothesis in the smallest of nutshells",
    "text": "The Iversen/Rosenbluth hypothesis in the smallest of nutshells\nVery (very) simply put, Iversen & Rosenbluth (2006, 2010) argue that women are politically to the left of men, other things equal, but also that this depends on macro-level factors – specifically on how countries’ economies are structured. In countries that have economies that rely strongly on specific skills (think: highly trained craftsmen and -women that are really good at a few specific tasks), this gap should be particularly large. In contrast, in countries that rely more on general skills (think: flexible professionals that can quickly switch between jobs), women and men should be more equal in their political opinions."
  },
  {
    "objectID": "posts/compa_survey/index.html#re-analysis-using-ess-data",
    "href": "posts/compa_survey/index.html#re-analysis-using-ess-data",
    "title": "Comparing people’s behavior and attitudes across countries",
    "section": "Re-analysis using ESS data",
    "text": "Re-analysis using ESS data\nWe do a new test of this hypothesis using data from the tenth (2018) round of the European Social Survey (ESS).\nOut of all the countries covered by this round of the ESS, we select the following two countries based on information we have from Iversen & Rosenbluth (2006), but also other studies (Hall and Soskice 2001; Iversen and Soskice 2001):\n\nIreland, which is known to rely strongly on general skills. Here, we expect a small gender gap.\nNorway, which relies on specific skills. Here, we expect a large gender gap.\n\nWe use the following micro-level variables from the ESS:\n\nLeft-right ideology (lrscale). This is measures people’s general political orientation and is the dependent variable.\nGender (gndr; male/female). This is the central independent variable here.\nHousehold income (hinctnta): This is a relevant control variable.\nAge (agea; years): Also a control variable.\nEducation (eduyrs): A final variable we want to control for.\n\n\nPackages\nWe use the tidyverse for data management & visualization and texreg to present regression results:\n\nlibrary(tidyverse)\nlibrary(texreg)\n\n\n\nSet theme for graphs\nThe classic theme just looks better…\n\ntheme_set(theme_classic())\n\n\n\nData import\nYou can download the data for free (after a registration) from https://www.europeansocialsurvey.org/. I use the .dta (Stata) version and saved the dataset as ESS10.dta on my computer. I use the haven package to import the dataset, and then immediately convert the dataset to the traditional R format with labelled::unlabelled (to be able to do this, you need to have both of these packages installed. Loading them with library() is not necessary).\n\ness &lt;- labelled::unlabelled(haven::read_dta(\"ESS10.dta\"))\n\n\n\nTrimming\nThe entire ESS is massive. To make things easier to handle, we select only the relevant variables (plus some useful “administrative” ones such as idno, essround, and cntry):\n\ness %&gt;% \n  select(idno,essround,cntry,lrscale,gndr,agea,eduyrs,hinctnta) -&gt; ess\n\n\n\nData cleaning\nHousehold income (hinctnta) and left-right self-placement (lrscale) are factors and need to be correctly converted to numeric before we can use them in a regression analysis:\n\nclass(ess$hinctnta)\n\n[1] \"factor\"\n\nclass(ess$lrscale)\n\n[1] \"factor\"\n\nbst290::visfactor(dataset = ess,\n                  variable = \"hinctnta\") # no label/value divergence, no adjustment needed\n\n values          labels\n      1  J - 1st decile\n      2  R - 2nd decile\n      3  C - 3rd decile\n      4  M - 4th decile\n      5  F - 5th decile\n      6  S - 6th decile\n      7  K - 7th decile\n      8  P - 8th decile\n      9  D - 9th decile\n     10 H - 10th decile\n\nbst290::visfactor(dataset = ess,\n                  variable = \"lrscale\") # labels/values are off by 1, needs to be adjusted\n\n values labels\n      1   Left\n      2      1\n      3      2\n      4      3\n      5      4\n      6      5\n      7      6\n      8      7\n      9      8\n     10      9\n     11  Right\n\ness %&gt;% \n  mutate(hhinc = as.numeric(hinctnta),\n         lrscale = as.numeric(lrscale) - 1) -&gt; ess\n\n\n\nCountry selection\nThe final “trimming” operation we need to do is to select only the two countries we want to compare. This is easy to do with filter(), and we create separate datasets for each of the two countries:\n\nunique(ess$cntry)\n\n [1] \"BE\" \"BG\" \"CH\" \"CZ\" \"EE\" \"FI\" \"FR\" \"GB\" \"GR\" \"HR\" \"HU\" \"IE\" \"IS\" \"IT\" \"LT\"\n[16] \"ME\" \"MK\" \"NL\" \"NO\" \"PT\" \"SI\" \"SK\"\n\ness %&gt;% \n  filter(cntry==\"NO\") -&gt; norway\n\ness %&gt;% \n  filter(cntry==\"IE\") -&gt; ireland\n\n\n\nDescriptive analysis of political gender gaps by country\nIt is good practice to first do a bit of visual analysis to get a sense of how the data look before moving to more complicated statistical analyses. Here, we use a bit of dplyr (group_by() & summarize()) to calculate the political gender gap in each country – how men and women differ, on average, in their ideology – and then visualize the result with a ggplot() bar graph.\nireland %&gt;%\n  group_by(gndr) %&gt;% \n  summarise(avg_lr = mean(lrscale, na.rm = T)) %&gt;% \n  ggplot(aes(x = gndr, y = avg_lr)) +\n    geom_bar(stat = \"identity\") +\n    geom_text(aes(label = round(avg_lr, digits = 1)), vjust = -.5) +\n    scale_y_continuous(limits = c(0,6)) +\n    labs(x = \"Gender\", y = \"Average left-right placement\",\n         caption = \"Higher scores = more conservative\",\n         title = \"Ireland\")\nnorway %&gt;%\n  group_by(gndr) %&gt;% \n  summarise(avg_lr = mean(lrscale, na.rm = T)) %&gt;% \n  ggplot(aes(x = gndr, y = avg_lr)) +\n    geom_bar(stat = \"identity\") +\n    geom_text(aes(label = round(avg_lr, digits = 1)), vjust = -.5) +\n    scale_y_continuous(limits = c(0,6)) +\n    labs(x = \"Gender\", y = \"Average left-right placement\",\n         caption = \"Higher scores = more conservative\",\n         title = \"Norway\")\n\n\n\n\n\n\n\n\n\n\nIt looks like the data support the hypothesis. We expected a small ideological gap between men and women in Ireland, and that is what we find: Men and women hardly differ on average in their left-right orientation (5.3 - 5.2 = 0.1). In contrast, this difference is four times as large (5.2 - 4.8 = 0.4), which is what we would have expected.\n\n\nRegression analysis\nWhile the visual analysis is useful, we also need to do a more thorough test where we control for other variables. To do that, we do a simple linear (OLS) regression analysis separately for each country:\n\n# Baseline model\nno_mod1 &lt;- lm(lrscale ~ gndr,\n               data = norway)\n\n# With controls\nno_mod2 &lt;- lm(lrscale ~ gndr + agea + eduyrs + hhinc,\n               data = norway)\n\n# Baseline model\nie_mod1 &lt;- lm(lrscale ~ gndr,\n               data = ireland)\n\n# With controls\nie_mod2 &lt;- lm(lrscale ~ gndr + agea + eduyrs + hhinc,\n               data = ireland)\n\nWe use screenreg() from the texreg package to show the results directly next to each other so that we can spot differences between the two countries more easily:\n\nscreenreg(list(no_mod1,no_mod2,ie_mod1,ie_mod2),\n          stars = 0.05,\n          custom.header = list(\"Norway\" = 1:2, \"Ireland\" = 3:4),\n          custom.model.names = c(\"No controls\",\"Controls\",\n                                 \"No controls\",\"Controls\"),\n          custom.coef.map = list(\"(Intercept)\" = \"Intercept\",\n                                 \"gndrFemale\" = \"Female\",\n                                 \"agea\" = \"Age\",\n                                 \"eduyrs\" = \"Education (years)\",\n                                 \"hhinc\" = \"Household income (deciles)\"))\n\n\n=========================================================================\n                                    Norway                 Ireland       \n                            ----------------------  ---------------------\n                            No controls  Controls   No controls  Controls\n-------------------------------------------------------------------------\nIntercept                      5.21 *       5.41 *     5.26 *      4.61 *\n                              (0.09)       (0.35)     (0.08)      (0.38) \nFemale                        -0.41 *      -0.38 *    -0.02       -0.03  \n                              (0.13)       (0.13)     (0.11)      (0.13) \nAge                                         0.01 *                 0.02 *\n                                           (0.00)                 (0.00) \nEducation (years)                          -0.10 *                -0.01  \n                                           (0.02)                 (0.02) \nHousehold income (deciles)                  0.12 *                -0.03  \n                                           (0.03)                 (0.03) \n-------------------------------------------------------------------------\nR^2                            0.01         0.04       0.00        0.03  \nAdj. R^2                       0.01         0.04      -0.00        0.02  \nNum. obs.                   1375         1300       1516         993     \n=========================================================================\n* p &lt; 0.05\n\n\nWomen are again significantly more to the left than men in Norway but not in Ireland – which is what Iversen & Rosenbluth would have predicted. These effects are barely affected by the inclusion of controls for age, education, and household income.\nOverall, this relatively simple re-test supports the Iversen/Rosenbluth theory of gender differences."
  },
  {
    "objectID": "posts/compa_survey/index.html#next-steps",
    "href": "posts/compa_survey/index.html#next-steps",
    "title": "Comparing people’s behavior and attitudes across countries",
    "section": "Next steps",
    "text": "Next steps\nYou have now seen how you can do a simple cross-country comparative analysis of survey data with R. Obviously, you can adapt this type of analysis to many different questions so long as you have relevant data. For example, if you have macro-level indicators of how countries’ electoral systems look like (which you do: https://cpds-data.org/) and comparative survey data on people’s electoral behavior (which you can get via the ESS), you can test if rates of participation in election differ between types of electoral systems. The same applies to any combination of macro-level factor and micro-level behavior you can think of and have data for.\nImportantly, you may also have noticed that we did not use any form of quantitative data to measure macro-level factors or to pick countries – we simply relied on findings from other studies to select relevant countries.\nFinally, there are obviously ways to make this type of analysis more sophisticated. One additional step one can take is to test statistically if the coefficients from regression models are statistically significantly different from each other. Paternoster et al. (1998) have developed a simple formula for this that works basically like a standard two-sample t-test.\nThe most advanced way to compare survey data from different countries is obviously with a multi-level or hierarchical regression analysis. This is what academic researchers usally use because it multi-level regression models make it possible to use all available data from a comparative survey dataset instead of picking only a small number of countries. This makes it possible to estimate more complicated models and to get more accurate and reliable results. If you want to learn more about this, there is a series of articles that explains these models in a very intuitive and easy fashion (Merlo, Yang, et al. 2005; Merlo, Chaix, et al. 2005a, 2005b; Merlo et al. 2006; see also Steenbergen and Jones 2002), and the book by Finch et al. (2014) explains how you implement these models in R."
  },
  {
    "objectID": "posts/compa_survey/index.html#footnotes",
    "href": "posts/compa_survey/index.html#footnotes",
    "title": "Comparing people’s behavior and attitudes across countries",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee https://github.com/erikgahner/PolData?tab=readme-ov-file#cross-sectional for a list of comparative survey data projects.↩︎\nObviously, questionnaires are translated where languages differ, and there are sometimes cases where some questions are only asked in a subset of all countries that are included in a given survey.↩︎"
  },
  {
    "objectID": "posts/measuringclass/index.html",
    "href": "posts/measuringclass/index.html",
    "title": "Measuring class with survey data",
    "section": "",
    "text": "Class is a key concept in the social and political sciences, and it explains many important phenomena, from party preferences and voting over social attitudes to health outcomes (e.g., Elo 2009; Gingrich 2017; Schwander and Häusermann 2013; Häusermann et al. 2022; Evans 2000). Therefore, it is important for every empirical social and political researcher to know how to measure people’s positions in class structures.\nSociologists have spent a lot of time on developing class schemes that make the abstract concept of “class” empirically measurable. The probably most famous class scheme is the Erikson-Goldthorpe-Portocarero (EGP) class scheme that was developed in the 1970s (Erikson, Goldthorpe, and Portocarero 1979), but there are also more recent schemes that take into account the fact that, as a result of technological change, increased educational attainment, and other factors, societies and labor markets in the 21st century look quite different than they did in the 1970s or 1980s. Daniel Oesch’s (2006) scheme is an important modern class scheme.\nThe basis for class schemes is generally occupation – what job does someone have? For example, someone who is a medical doctor would typically be seen as a “higher-skilled professional”, whereas a welder would usually be classified as a “skilled manual worker”. People’s occupations are usually measured with occupational classification schemes, the most widely used is the International Labour Organization’s (ILO) International Standard Classification of Occupations (ISCO) scheme.1 This scheme comes in different versions reflecting the years they were adopted: ISCO-68, ISCO-88, and ISCO-08.\nThere are of course some people who’s occupation is being self-employed – they run their own businesses, which can be a small one-person business (e.g., a shop) but it can also be a medium-sized company with 500 employees. Obviously, this has effects on their class membership: A small shop owner would often be considered to be a member of the “petite bourgeoisie”, while someone who owns a larger company might be considered a “capital owner”."
  },
  {
    "objectID": "posts/measuringclass/index.html#class-still-matters",
    "href": "posts/measuringclass/index.html#class-still-matters",
    "title": "Measuring class with survey data",
    "section": "",
    "text": "Class is a key concept in the social and political sciences, and it explains many important phenomena, from party preferences and voting over social attitudes to health outcomes (e.g., Elo 2009; Gingrich 2017; Schwander and Häusermann 2013; Häusermann et al. 2022; Evans 2000). Therefore, it is important for every empirical social and political researcher to know how to measure people’s positions in class structures.\nSociologists have spent a lot of time on developing class schemes that make the abstract concept of “class” empirically measurable. The probably most famous class scheme is the Erikson-Goldthorpe-Portocarero (EGP) class scheme that was developed in the 1970s (Erikson, Goldthorpe, and Portocarero 1979), but there are also more recent schemes that take into account the fact that, as a result of technological change, increased educational attainment, and other factors, societies and labor markets in the 21st century look quite different than they did in the 1970s or 1980s. Daniel Oesch’s (2006) scheme is an important modern class scheme.\nThe basis for class schemes is generally occupation – what job does someone have? For example, someone who is a medical doctor would typically be seen as a “higher-skilled professional”, whereas a welder would usually be classified as a “skilled manual worker”. People’s occupations are usually measured with occupational classification schemes, the most widely used is the International Labour Organization’s (ILO) International Standard Classification of Occupations (ISCO) scheme.1 This scheme comes in different versions reflecting the years they were adopted: ISCO-68, ISCO-88, and ISCO-08.\nThere are of course some people who’s occupation is being self-employed – they run their own businesses, which can be a small one-person business (e.g., a shop) but it can also be a medium-sized company with 500 employees. Obviously, this has effects on their class membership: A small shop owner would often be considered to be a member of the “petite bourgeoisie”, while someone who owns a larger company might be considered a “capital owner”."
  },
  {
    "objectID": "posts/measuringclass/index.html#what-information-do-you-need-and-where-do-you-get-it",
    "href": "posts/measuringclass/index.html#what-information-do-you-need-and-where-do-you-get-it",
    "title": "Measuring class with survey data",
    "section": "What information do you need, and where do you get it?",
    "text": "What information do you need, and where do you get it?\nClass is an individual-level variable: A person can be a member of the working class, but a country cannot. This means that we use individual-level data – survey data – to measure class. Such survey data need to contain three pieces of information (variables) that reflect people’s class membership:\n\nTheir occupation. This needs to be measured at the highest level of detail, meaning with the four-digit ISCO-88 or ISCO-08 scheme.\nWhether or not they are self-employed.\nIf they are self-employed, how many employees they have.\n\nMany survey datasets contain this information in some form, but it is usually easiest to use either data from large and well-known comparative social survey projects like the International Social Survey Project (ISSP) or the European Social Survey (ESS).2 Both are free to use (but you do need to register as a user). Many national survey projects also contain that information, but occupation is often coded based on the ISCO scheme but based on national occupational classification schemes (e.g., ANZSCO for Australia and New Zealand or SOC for the United States). These can be translated to the ISCO scheme with specific conversion tables, but this often takes quite a bit of time and effort.\nTechnically speaking, applying a class scheme to survey data is quite a bit of work because you need to go over a long list of occupations – the four-digit ISCO08 scheme contains 473 different occupations – and decide which class they belong to. Following this, you have to write code to group all the different observations in your dataset into their classes. Obviously, this would take a lot of time.\nFortunately, people have written packages for R that make this a quick and (normally) easy thing to do. Two relevant packages are the DIGCLASS package, which was developed by researchers at the EU, and the occupar package.3\nThe rest of this tutorial shows how you can measure people’s class with data from the ISSP and using the DIGCLASS package for R. Most of this also applies if you work with data from the ESS, but some data import and cleaning steps might be different. Below is an example of how your dataset needs to look like that you can use to guide your data cleaning and preparation when you work with the ESS."
  },
  {
    "objectID": "posts/measuringclass/index.html#installing-the-digclass-package",
    "href": "posts/measuringclass/index.html#installing-the-digclass-package",
    "title": "Measuring class with survey data",
    "section": "Installing the DIGCLASS package",
    "text": "Installing the DIGCLASS package\nThe DIGCLASS package is not on CRAN (the official R “app store”), but you can install it with the remotes-package (which you need to have installed first, of course):\n\n# install.packages(\"remotes\")\nremotes::install_git(\"https://code.europa.eu/digclass/digclass.git\")\n\nNext, we load the package with library(), in addition to the tidyverse package:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(DIGCLASS)\ntheme_set(theme_classic())"
  },
  {
    "objectID": "posts/measuringclass/index.html#getting-issp-data",
    "href": "posts/measuringclass/index.html#getting-issp-data",
    "title": "Measuring class with survey data",
    "section": "Getting ISSP data",
    "text": "Getting ISSP data\nIn this tutorial, we will work with data from the 2016 Role of Government round of the ISSP (v. 2.0.0; 19.09.2018), which you can download from the GESIS data repository: https://www.gesis.org/en/issp/data-and-documentation/role-of-government/2016#c127852. As mentioned earlier, you need to register as a user, but this is free – and also gives you access to many other survey datasets like the Eurobarometer or the European Values Study.\nMake sure that you download the data in SPSS (.sav) format and that you store them in the folder that you are working in (ideally your RStudio Project folder)."
  },
  {
    "objectID": "posts/measuringclass/index.html#importing-the-dataset",
    "href": "posts/measuringclass/index.html#importing-the-dataset",
    "title": "Measuring class with survey data",
    "section": "Importing the dataset",
    "text": "Importing the dataset\nTo import the dataset, you can use the read_sav() function from the haven package. Important: Simply import the dataset for now, do not yet convert it with labelled::unlabelled()! I have stored the dataset as issp16.sav, so I need to specify this in my code – you obviously need to use the name that you gave your dataset file:\n\nissp &lt;- haven::read_sav(\"issp16.sav\")\n\nAs other large survey datasets, the ISSP dataset is very large and contains almost 400 variables:\n\ndim(issp)\n\n[1] 48720   395\n\n\nTo make things easier for now, we trim the data to the variables we actually need plus one variable (v19) that we can later use as a dependent variable in an example analysis:\n\nissp %&gt;% \n  select(studyno,country, # good to keep these in \n         ISCO08, # ISCO-08 occupational codes\n         EMPREL, # Employment relationship, to identify self-employed\n         NEMPLOY, # number of employees if self-employed\n         v19 # a variable measuring respondents' views on whether the government should spend more on the unemployed\n         ) -&gt; issp"
  },
  {
    "objectID": "posts/measuringclass/index.html#data-preparation",
    "href": "posts/measuringclass/index.html#data-preparation",
    "title": "Measuring class with survey data",
    "section": "Data preparation",
    "text": "Data preparation\nThe DIGCLASS package expects the data it works with to be in a specific format. If you for example call up the help file for the DIGCLASS::isco08_to_oesch() function with ?DIGCLASS::isco08_to_oesch and scroll down a bit, you see that the function needs three main inputs:\n\nx, which is the four-digit ISCO-08 scores. They need to be stored as text (character)\nself_employed, which needs to be a “numeric vector indicating whether each individual is self-employed (1) or an employee (0).”\nn_employees, which needs to be a “numeric vector indicating the number of employees under each respondent.”\n\nThis means we need to have three variables that correspond exactly to this: ISCO-08 scores as text, a 0/1 dummy indicating whether someone is self-employed, and a variable containing the number of employees for those who are self-employed.\n\nPreparing the ISCO-08 scores\nLet’s start the data preparation with ISCO08, and let’s first take a closer look at how it is stored now:\n\nclass(issp$ISCO08)\n\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n\n\nFrom the result of class(), we see that the variable is stored in a labelled-type format – which is because the dataset was imported with haven – and this is also the case for all the other variables (see the Environment).\nTo see a bit more clearly how the ISCO08 variable looks like, let’s look at the first few observations:\n\nissp %&gt;% \n  select(ISCO08) %&gt;% \n  slice_head(n = 10) # to get first ten observations\n\n# A tibble: 10 × 1\n   ISCO08                                                               \n   &lt;dbl+lbl&gt;                                                            \n 1 2611 [Lawyers]                                                       \n 2 2512 [Software developers]                                           \n 3 1212 [Human resource managers]                                       \n 4 1439 [Services managers not elsewhere classified]                    \n 5 4419 [Clerical support workers not elsewhere classified]             \n 6 1345 [Education managers]                                            \n 7 3230 [Traditional and complementary medicine associate professionals]\n 8 2654 [Film, stage and related directors and producers]               \n 9 2611 [Lawyers]                                                       \n10 5131 [Waiters]                                                       \n\n\nYou see that the first observation is a lawyer, which has the ISCO-08 code 2611, the next is a software developer (ISCO-08 code 2512), and so on.\nNow comes an important step: We need to convert the ISCO08 variable to a character-type variable – for some reason, the DIGCLASS package expects that the ISCO codes are stored as text (e.g., “2611”, “2512”), and that is what we need to deliver for the package to work.\nTo do that, we simply use as.character():\n\nissp %&gt;% \n  mutate(isco_nums_as_text = as.character(ISCO08)) -&gt; issp\n\nThe new variable should now be a character-type variable:\n\nclass(issp$isco_nums_as_text)\n\n[1] \"character\"\n\n\nThis means that the ISCO-08 scores are taken care off and we can move on to the next piece of information that we need: a 0/1 variable that tells us if people are self-employed.\n\n\n\nSelf-employment\nInformation about how people earn their living in general is contained in the EMPREL variable. To see how this looks like, we can quickly tabulate the individual categories:\n\ntable(issp$EMPREL)\n\n\n    1     2     3     4 \n33504  4169  1797  1185 \n\n\nUnfortunately, we only get numbers. This is because the dataset is still stored in the labelled format, and we can quickly fix this by using unlabelled():\n\nissp &lt;- labelled::unlabelled(issp)\n\nNow the tabulation should work as intended:\n\ntable(issp$EMPREL)\n\n\nNAP (Code 3 in WORK; NZ: Code 2-9 MAINSTAT) \n                                          0 \n                                   Employee \n                                      33504 \n            Self-employed without employees \n                                       4169 \n               Self-employed with employees \n                                       1797 \n          Working for own family's business \n                                       1185 \n                                  No answer \n                                          0 \n\n\nYou see that most respondents fall into the “Employee” category, but there are also people who are self-employed with and without employees. Some also work in a family business. Finally, there are some empty categories that have no observations, but we ignore them for now.\n\nAll we really need to do is to re-code this variable into a 0/1 dummy that is equal to 1 if people are self-employed and 0 otherwise. Here, we can use the case_match() function, which is simply put a more advanced version of if_else():\n\nissp %&gt;% \n  mutate(selfemp = case_match(EMPREL,\n                              c(\"Self-employed without employees\",\n                                \"Self-employed with employees\") ~ 1,\n                              c(\"Employee\",\"Working for own family's business\") ~ 0,\n                              .default = NA)) -&gt; issp\n\nMaybe you can already see that we are here telling R to create a new variable called selfemp that is 1 if the EMPREL variable is either “Self-employed without employees” or “Self-employed with employees” and 0 otherwise. To make sure that observations that do not fit either of these conditions are excluded, we specify .default = NA.\nWe can do a quick cross-tabulation to see if the re-coding worked as intended:\n\ntable(issp$EMPREL,issp$selfemp)\n\n                                             \n                                                  0     1\n  NAP (Code 3 in WORK; NZ: Code 2-9 MAINSTAT)     0     0\n  Employee                                    33504     0\n  Self-employed without employees                 0  4169\n  Self-employed with employees                    0  1797\n  Working for own family's business            1185     0\n  No answer                                       0     0\n\n\nIt looks like things did work: the self-employed are coded as 1, all others are 0.\n\n\nNumber of employees\nThe final variable we need is how many employees those respondents who are self-employed have. Here, we can use the NEMPLOY variable from the ISSP dataset, but let’s again begin by simply checking what type this variable is:\n\nclass(issp$NEMPLOY)\n\n[1] \"numeric\"\n\n\nThe variable is already numeric, which means we do not really have to do anything with it – it is good to go. But we can nevertheless quickly visualize it to see how it is distributed:\n\nissp %&gt;% \n  ggplot(aes(x = NEMPLOY)) +\n    geom_histogram(color = \"white\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 46996 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nThere are a few extreme outliers which make it difficult to see anything. We can get a clearer picture by removing those with more than 100 employees from the graph (obviously, we only do this for the graph!):\n\nissp %&gt;% \n  filter(NEMPLOY&lt;100) %&gt;% \n  ggplot(aes(x = NEMPLOY)) +\n    geom_histogram(color = \"white\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nMost respondents who have employees have only relatively small businesses with less than 25 employees."
  },
  {
    "objectID": "posts/measuringclass/index.html#generating-a-class-variable",
    "href": "posts/measuringclass/index.html#generating-a-class-variable",
    "title": "Measuring class with survey data",
    "section": "Generating a class variable",
    "text": "Generating a class variable\nWe now have all pieces of information we need and can get to the class variable. Let’s start by generating two of Daniel Oesch’s (2006) class schemes, the very simple one with five classes and the more advanced one with eight classes. Each can be generated with the isco08_to_oesch() function. The following code shows how to create both class schemes at once:\n\nissp %&gt;% \n  mutate(oesch_5 = DIGCLASS::isco08_to_oesch(x = isco_nums_as_text,\n                                             self_employed = selfemp,\n                                             n_employees = NEMPLOY,\n                                             n_classes = 5,\n                                             label = T,\n                                             to_factor = F),\n         oesch_8 = DIGCLASS::isco08_to_oesch(x = isco_nums_as_text,\n                                             self_employed = selfemp,\n                                             n_employees = NEMPLOY,\n                                             n_classes = 8,\n                                             label = T,\n                                             to_factor = F)) -&gt; issp\n\nℹ ISCO variable has occupations with digits less than 4. Converting to 4 digits.\n\n\n• Converted `110` to `0110`\n\n\n• Converted `310` to `0310`\n\n\n• Converted `210` to `0210`\n\n\nℹ ISCO variable has occupations with digits less than 4. Converting to 4 digits.\n\n\n• Converted `110` to `0110`\n\n\n• Converted `310` to `0310`\n\n\n• Converted `210` to `0210`\n\n\n\nLet’s have a look at the results:\n\ntable(issp$oesch_5)\n\n\n'Higher-grade service class'  'Lower-grade service class' \n                        6374                         7058 \n           'Skilled workers'      'Small business owners' \n                       12478                         1117 \n         'Unskilled workers' \n                        7558 \n\ntable(issp$oesch_8)\n\n\n                           '(Associate) managers' \n                                             5541 \n                                         'Clerks' \n                                             4043 \n                             'Production workers' \n                                             8309 \n'Self-employed professionals and large employers' \n                                              493 \n                                'Service workers' \n                                             7684 \n                          'Small business owners' \n                                             1117 \n            'Socio-cultural (semi-)professionals' \n                                             4667 \n                 'Technical (semi-)professionals' \n                                             2731 \n\n\nAnd we have what we want: Two class schemes, one simpler and the other a bit more detailed. The second one is used by for example Gingrich (2017) or Schwander & Häusermann (2013).4"
  },
  {
    "objectID": "posts/measuringclass/index.html#example-analysis",
    "href": "posts/measuringclass/index.html#example-analysis",
    "title": "Measuring class with survey data",
    "section": "Example analysis",
    "text": "Example analysis\nLet’s say we wanted to find out if people’s class has an effect on how they think about the welfare state, specifically whether the government should do more to support the unemployed. As mentioned earlier, the ISSP includes a variable that measures these attitudes and which looks like this:\n\nclass(issp$v19)\n\n[1] \"factor\"\n\ntable(issp$v19)\n\n\n             NAV (PH)       Spend much more            Spend more \n                    0                  7209                 12422 \nSpend the same as now            Spend less       Spend much less \n                16760                  6546                  2390 \n         Can't choose             No answer \n                    0                     0 \n\n\nThe variable is stored as a factor (i.e., as a categorical variable), but it has five categories – so we can, sort of, get away with treating it as if it were numeric (this is what Thewissen and Rueda 2019 also do). To be able to do that, we first have to check how it looks internally and then convert it:\n\nbst290::visfactor(dataset = issp,\n                  variable = \"v19\")\n\n values                labels\n      1              NAV (PH)\n      2       Spend much more\n      3            Spend more\n      4 Spend the same as now\n      5            Spend less\n      6       Spend much less\n      7          Can't choose\n      8             No answer\n\n\nThere is a bit of a divergence between values and labels – the NAV (PH) category is empty (see above), which means the lowest actual category has the value of 2 and so on. We can fix this by simply using droplevels() to get rid of empty categories and then as.numeric().\nOne thing we need to pay attention to is that, right now, lower scores correspond to more support for government aid to the unemployed. This is a bit strange to work with, so we reverse the scale of the new variable by subtracting it from 6 (so that the score of 1 becomes 6-1 = 5, 2 becomes 6-2 = 4, and so on:)\n\nissp %&gt;% \n  mutate(v19 = droplevels(v19),\n         unemspend = 6 - as.numeric(v19)) -&gt; issp\n\nThe new numeric variable has values from 1 to 5, which is what we want:\n\ntable(issp$unemspend)\n\n\n    1     2     3     4     5 \n 2390  6546 16760 12422  7209 \n\n\nLet’s now see to class influences attitudes toward help for the unemployed in Sweden (it is important to focus on one country alone, otherwise a simple linear regression model will give wrong results!):\n\nissp %&gt;% \n  filter(country == \"SE-Sweden\") -&gt; swe_data\n\nmod1 &lt;- lm(unemspend ~ oesch_5,\n           data = swe_data)\nsummary(mod1)\n\n\nCall:\nlm(formula = unemspend ~ oesch_5, data = swe_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.38053 -0.38053  0.03929  0.43478  2.43478 \n\nCoefficients:\n                                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                         2.80315    0.05211  53.793  &lt; 2e-16 ***\noesch_5'Lower-grade service class'  0.15756    0.07196   2.190   0.0288 *  \noesch_5'Skilled workers'            0.50707    0.07234   7.010 4.56e-12 ***\noesch_5'Small business owners'     -0.23793    0.18084  -1.316   0.1886    \noesch_5'Unskilled workers'          0.57738    0.09391   6.148 1.16e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8305 on 939 degrees of freedom\n  (196 observations deleted due to missingness)\nMultiple R-squared:  0.07685,   Adjusted R-squared:  0.07291 \nF-statistic: 19.54 on 4 and 939 DF,  p-value: 1.842e-15\n\n\nAs always, one category (here: “Higher-grade service class”) is omitted from the model and the coefficients show us the difference from each other class to the omitted one. This means that all classes except for small business owners are significantly more supportive of government help for the unemployed than the higher-grade service class.\nTo get a better sense, we can use prediction::prediction_summary() to get predicted support scores per class based on the model:\n\nprediction::prediction_summary(model = mod1,\n                               at = list(oesch_5 = unique(na.omit(swe_data$oesch_5))))\n\n                  at(oesch_5) Prediction      SE     z         p lower upper\n            'Skilled workers'      3.310 0.05017 65.98 0.000e+00 3.212 3.409\n 'Higher-grade service class'      2.803 0.05211 53.79 0.000e+00 2.701 2.905\n  'Lower-grade service class'      2.961 0.04963 59.65 0.000e+00 2.863 3.058\n          'Unskilled workers'      3.381 0.07813 43.27 0.000e+00 3.227 3.534\n      'Small business owners'      2.565 0.17317 14.81 1.202e-49 2.226 2.905\n\n\n\nWe can get an ever better picture of the results if we just visualize the result:\n\nprediction::prediction_summary(model = mod1,\n                               at = list(oesch_5 = unique(na.omit(swe_data$oesch_5)))) %&gt;% \n  ggplot(aes(x = Prediction, \n             y = reorder(`at(oesch_5)`,Prediction), \n             xmin = lower, xmax = upper)) +\n    geom_point(stat = \"identity\") +\n    geom_linerange() +\n    scale_x_continuous(breaks = seq(1,5,1),\n                       limits = c(1,5)) +\n    labs(x = \"Predicted support for government aid to the unemployed\",\n         y = \"Class\", caption = \"95% confidence intervals\")\n\n\n\n\n\n\n\n\nNote that we use reorder() to arrange the classes from highest to lowest support. Clearly, small business owners in Sweden are least supportive of government help for the unemployed, while unskilled and skilled workers (i.e., the “working class”) are most supportive. Looks like class does still matter in Sweden!"
  },
  {
    "objectID": "posts/measuringclass/index.html#footnotes",
    "href": "posts/measuringclass/index.html#footnotes",
    "title": "Measuring class with survey data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee also https://isco-ilo.netlify.app/en/isco-08/#download-isco-08-material↩︎\nSee https://issp.org/ and https://www.europeansocialsurvey.org/.↩︎\nSee https://code.europa.eu/digclass/digclass and https://github.com/DiogoFerrari/occupar.↩︎\nGingrich calls “socio-cultural (semi-) professionals” the “new middle class”, “technical (semi-) professionals”, “clerks”, and “(Associate) managers” are the “old middle class”, “service workers” are the “new working class”, and “Production workers” are the “old working class”. If you wanted, you could use case_match() to re-code the oesch_5 variable into a new and simpler class scheme that corresponds to what Gingrich is using.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Testing big ideas with simple methods",
    "section": "",
    "text": "Many students have grand ideas – e.g., about the role of class, social norms, political institutions, or gender in politics, society, or the economy – but they don’t quite know how to actually test these ideas in an empirical analysis. Often, the problem seems to be that they think they need to do something very complicated, similar to what “adult” researchers publish in academic journal articles. But this is wrong: Many big ideas can be tested with (relatively) simple methods. This blog shows how this works in practice and with open-source software (R).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‘I can’t find any data!’\n\n\n\n\n\n\nData\n\n\nPolitical science\n\n\nSociology\n\n\n\n\n\n\n\n\n\nApr 6, 2025\n\n\nCarlo Knotz\n\n\n\n\n\n\n\n\n\n\n\n\nComparing countries with macro-level data\n\n\n\n\n\n\nMacro\n\n\nComparing countries\n\n\nEconomics\n\n\nPolitical science\n\n\nSociology\n\n\n\n\n\n\n\n\n\nMar 30, 2025\n\n\nCarlo Knotz\n\n\n\n\n\n\n\n\n\n\n\n\nHow vulnerable are workers to globalization (and what effects does this have)?\n\n\n\n\n\n\nSurvey data\n\n\nGlobalization\n\n\nMerging data\n\n\nESS\n\n\nPolitical science\n\n\nSociology\n\n\nEconomics\n\n\n\n\n\n\n\n\n\nMar 10, 2025\n\n\nCarlo Knotz\n\n\n\n\n\n\n\n\n\n\n\n\nComparing people’s behavior and attitudes across countries\n\n\n\n\n\n\nSurvey data\n\n\nComparing countries\n\n\nGender\n\n\nESS\n\n\nPolitical science\n\n\nSociology\n\n\n\n\n\n\n\n\n\nMar 8, 2025\n\n\nCarlo Knotz\n\n\n\n\n\n\n\n\n\n\n\n\nMeasuring class with survey data\n\n\n\n\n\n\nSurvey data\n\n\nClass\n\n\nISSP\n\n\nPolitical science\n\n\nSociology\n\n\n\n\n\n\n\n\n\nMar 8, 2025\n\n\nCarlo Knotz\n\n\n\n\n\n\nNo matching items"
  }
]