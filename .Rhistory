extracted |>
select(clean_text, politician)
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_extract(clean_text, "political party",
pred_name = "party",
additional_prompt = "return NA if the tweet does not explicitly mention a French political party") -> extracted
end <- Sys.time()
diff <- end-start
diff
extracted |>
select(clean_text, party)
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_extract(clean_text, "French politician",
pred_name = "politician",
additional_prompt = "return NA if the tweet does not explicitly mention a French politician") -> extracted
end <- Sys.time()
diff <- end-start
diff
extracted |>
select(clean_text, politician)
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_extract(clean_text, "French politician", #,additional_prompt = "return NA if the tweet does not explicitly mention a French politician"
pred_name = "politician") -> extracted
end <- Sys.time()
diff <- end-start
diff
extracted |>
select(clean_text, politician)
checked |>
select(clean_text,lepen)
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_extract(clean_text, "French politician",
additional_prompt = "return NA if the tweet does not explicitly mention a French politician",
pred_name = "politician") -> extracted
end <- Sys.time()
diff <- end-start
diff
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_extract(clean_text, "French politician",
pred_name = "politician") -> extracted
end <- Sys.time()
diff <- end-start
diff
rm(extracted)
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_extract(clean_text, "French politician",
pred_name = "politician") -> extracted
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_extract(clean_text, "French politician",
additional_prompt = "return NA if the tweet does not explicitly mention a French politician",
pred_name = "politician") -> extracted
extracted |>
select(clean_text, politician)
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_extract(clean_text, "French politician",
pred_name = "politician") -> extracted
end <- Sys.time()
diff <- end-start
diff
extracted |>
select(clean_text, politician)
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_extract(clean_text, "French politician",
additional_prompt = "return NA if the tweet does not explicitly mention a French politician",
pred_name = "politician") -> extracted
end <- Sys.time()
diff <- end-start
diff
extracted |>
select(clean_text, politician)
extracted |>
select(clean_text, politician)
library(mall)
llm_use("ollama","llama3.1",
seed = 42)
library(tidyverse)
tweets <- read.csv("https://zenodo.org/records/7347479/files/FR-R-MIGR-TWIT-2011-2022_meta.csv?download=1", sep = ";")
glimpse(tweets)
tweets |>
slice_head(n = 10) |>
select(data__text)
tweets |>
filter(data__id != "data__id" & data__id!="") -> tweets
tweets |>
mutate(clean_text = str_remove_all(data__text, "@|#|http?://\\S+")) -> tweets
tweets |>
slice_head(n = 10) |>
select(clean_text)
start <- Sys.time()
tweets |>
slice_head(n = 10) |>
select(data__text) |>
llm_translate(data__text,
language = "english") -> translated
end <- Sys.time()
diff <- end-start
diff
translated |>
select(.translation)
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_verify(clean_text, "does this tweet mention social fraud?",
pred_name = "socialfraud") -> checked
end <- Sys.time()
diff <- end-start
diff
checked |>
select(clean_text,socialfraud)
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_verify(clean_text, "does this tweet mention Marine Le Pen?",
pred_name = "lepen") -> checked
end <- Sys.time()
diff <- end-start
diff
checked |>
select(clean_text,lepen)
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_extract(clean_text, "French politician",
pred_name = "politician") -> extracted
end <- Sys.time()
diff <- end-start
diff
extracted |>
select(clean_text, politician)
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_extract(clean_text, "French politician",
additional_prompt = "return NA if the tweet does not explicitly mention a French politician",
pred_name = "politician") -> extracted
end <- Sys.time()
diff <- end-start
diff
library(mall)
llm_use("ollama","llama3.1",
seed = 42)
library(tidyverse)
tweets <- read.csv("https://zenodo.org/records/7347479/files/FR-R-MIGR-TWIT-2011-2022_meta.csv?download=1", sep = ";")
glimpse(tweets)
tweets |>
slice_head(n = 10) |>
select(data__text)
tweets |>
filter(data__id != "data__id" & data__id!="") -> tweets
tweets |>
mutate(clean_text = str_remove_all(data__text, "@|#|http?://\\S+")) -> tweets
tweets |>
slice_head(n = 10) |>
select(clean_text)
start <- Sys.time()
tweets |>
slice_head(n = 10) |>
select(data__text) |>
llm_translate(data__text,
language = "english") -> translated
end <- Sys.time()
diff <- end-start
diff
translated |>
select(.translation)
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_verify(clean_text, "does this tweet mention social fraud?",
pred_name = "socialfraud") -> checked
end <- Sys.time()
diff <- end-start
diff
checked |>
select(clean_text,socialfraud)
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_verify(clean_text, "does this tweet mention Marine Le Pen?",
pred_name = "lepen") -> checked
end <- Sys.time()
diff <- end-start
diff
checked |>
select(clean_text,lepen)
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_extract(clean_text, "French politician",
pred_name = "politician") -> extracted
end <- Sys.time()
diff <- end-start
diff
extracted |>
select(clean_text, politician)
start <- Sys.time()
tweets %>%
select(clean_text) %>%
slice_head(n = 10) %>%
llm_extract(clean_text, "French politician",
additional_prompt = "return NA if the tweet does not explicitly mention a French politician",
pred_name = "politician") -> extracted
end <- Sys.time()
diff <- end-start
diff
extracted |>
select(clean_text, politician)
library(mall)
llm_use("ollama","llama3.1")
library(tidyverse)
tweets <- read.csv("https://zenodo.org/records/7347479/files/FR-R-MIGR-TWIT-2011-2022_meta.csv?download=1", sep = ";")
library(tidyverse)
theme_set(theme_classic())
ess7 <- haven::read_dta("/Users/carloknotz/Documents/Work/Stavanger/Teaching/Statistics/bst290_tutorials_site/ess7.dta")
ess7 %>%
select(idno,cntry,essround,isco08,gndr,agea,trstplt) -> ess7
scores <- haven::read_dta("/Users/carloknotz/Documents/R-code/task.dta")
head(scores)
summary(scores$BK)
scores %>%
arrange(-BK) %>%
head()
scores %>%
arrange(BK) %>%
head()
ess7 %>%
mutate(isco08_scores = as.numeric(isco08)) -> ess7
head(ess7)
ess7 %>%
mutate(isco88 = occupar::isco08to88(isco08_scores)) -> ess7
head(ess7)
ess7 %>%
mutate(isco88_2d = as.numeric(substr(as.character(isco88), 1,2))) -> ess7
ess7 %>%
relocate(idno,cntry,essround,isco08,isco88,isco88_2d) %>%
head()
scores %>%
mutate(isco88_2d = as.numeric(occupation)) -> scores
ess7 %>%
left_join(scores, by = "isco88_2d") -> ess7
ess7 %>%
select(idno,isco08,isco88_2d,BK,RTI_alm_isco_77) %>%
head()
ess7 <- labelled::unlabelled(ess7)
ess7 %>%
group_by(gndr) %>%
summarise(avg_BK = mean(BK, na.rm = T)) %>%
drop_na() %>%
ggplot(aes(x = gndr, y = avg_BK)) +
geom_col()
#| classes: preview-image
ess7 %>%
group_by(occupation) %>%
summarise(avg_age = mean(agea, na.rm = T),
avg_BK = mean(BK, na.rm = T)) %>%
drop_na() %>%
ggplot(aes(x = avg_age, y = avg_BK)) +
geom_point() +
geom_text(aes(label = occupation), vjust = 1,
color = "grey",
size = 3) +
geom_smooth(method = "lm", color = "grey",
linetype = "dashed", se = F) +
labs(x = "Average age in occupational group",
y = "Average offshoreability")
ess7 %>%
drop_na(trstplt,BK) %>%
ggplot(aes(x = trstplt, y = BK)) +
geom_count()
#geom_hex(binw
ess7 %>%
drop_na(trstplt,BK) %>%
ggplot(aes(y = trstplt, x = BK)) +
geom_count()
ess7 %>%
drop_na(trstplt,BK) %>%
ggplot(aes(y = trstplt, x = BK)) +
geom_count() +
geom_smooth()
ess7 %>%
drop_na(trstplt,BK) %>%
ggplot(aes(y = trstplt, x = BK)) +
geom_count() +
geom_smooth(method = "lm")
ess7 %>%
drop_na(trstplt,BK) %>%
ggplot(aes(y = trstplt, x = BK)) +
geom_point() +
geom_smooth(method = "lm")
ess7
ess7 %>%
ungroup() +
drop_na(trstplt,BK) %>%
ggplot(aes(y = trstplt, x = BK)) +
geom_point() +
geom_smooth(method = "lm")
ess7 %>%
ungroup() |>
drop_na(trstplt,BK) %>%
ggplot(aes(y = trstplt, x = BK)) +
geom_point() +
geom_smooth(method = "lm")
ess7 %>%
drop_na(trstplt,BK) %>%
ggplot(aes(y = trstplt, x = BK)) +
geom_hex(binwidth = c(1,.75))
ess7
ess7 %>%
drop_na(trstplt,BK) %>%
ggplot(aes(y = as.numeric(trstplt)-1, x = BK)) +
geom_hex(binwidth = c(1,.75))
ess7 %>%
drop_na(trstplt,BK) %>%
ggplot(aes(y = as.numeric(trstplt)-1, x = BK)) +
geom_count()
table(ess7$trstplt)
bst290::visfactor(dataset = ess7, variable = "trstplt")
ess7 %>%
drop_na(trstplt,BK) %>%
mutate(trstplt_num = as.numeric(trstplt)-1)
ggplot(aes(y = trstplt_num, x = BK)) +
geom_count()
ess7 %>%
drop_na(trstplt,BK) %>%
mutate(trstplt_num = as.numeric(trstplt)-1)
ggplot(aes(y = trstplt_num, x = BK)) +
geom_count()
ess7 %>%
drop_na(trstplt,BK) %>%
mutate(trstplt_num = as.numeric(trstplt)-1) %>%
ggplot(aes(y = trstplt_num, x = BK)) +
geom_count()
ess7 %>%
drop_na(trstplt,BK) %>%
mutate(trstplt_num = as.numeric(trstplt)-1) %>%
ggplot(aes(y = trstplt_num, x = BK)) +
geom_hex(binwidth = c(1,.75))
ess7 %>%
drop_na(trstplt,BK) %>%
mutate(trstplt_num = as.numeric(trstplt)-1) %>%
ggplot(aes(y = trstplt_num, x = BK)) +
geom_hex(binwidth = c(.75,1))
parallel::detectCores()
# Chunk 1
library(tidyverse)
theme_set(theme_classic())
ged <- readRDS("/Users/carloknotz/Documents/Data/UCDP_GED/organizedviolencecy_v25_1.rds")
qog <- haven::read_dta("/Users/carloknotz/Documents/Data/QoG/qog_bas_ts_jan25.dta")
# ged %>%
#   filter(!(country_cy %in% c("German Democratic Republic","Yemen (South Yemen)","Czechoslovakia"))) -> ged
#
# qog %>%
#   filter(year>=1989) -> qog
# Chunk 2
head(bst290::ess[,1:5])
# Chunk 3
data(airquality)
head(airquality)
# Chunk 4
qog %>%
filter(cname %in% c("Norway","Sweden") & year %in% c(1994,1995,1996)) %>%
select(cname,ccodealp,year)
qog %>%
filter(cname %in% c("Norway","Sweden") & year %in% c(1994,1995,1996)) %>%
select(cname,ccodealp,year) -> tscs
# Chunk 5
library(tidyverse)
tscs %>%
{anyDuplicated(select(., cname)) == 0}
# Chunk 6
tscs %>%
{anyDuplicated(select(., cname,year)) == 0}
# Chunk 8
tscs
# Chunk 9
tscs %>%
mutate(ccode_2d = countrycode::countrycode(sourcevar = ccodealp,
origin = "iso3c",
destination = "iso2c"))
# Chunk 10
rm(tscs,airquality)
# Chunk 12
qog %>%
{anyDuplicated(select(., cname,year)) == 0}
ged %>%
{anyDuplicated(select(., country_cy,year_cy)) == 0}
# Chunk 13
qog %>%
filter(duplicated(.[,c("cname","year")])) -> duplicates
unique(duplicates$cname)
rm(duplicates)
# Chunk 14
qog %>%
filter(cname=="Chile") %>%
head()
qog %>%
filter(cname=="Syrian Arab Republic (the)") %>%
head()
qog %>%
filter(cname=="Indonesia") %>%
head()
# Chunk 15
qog %>%
filter(!(cname %in% c("Chile","Indonesia",
"Syrian Arab Republic (the)",
"Congo (the Democratic Republic of the)"))) -> qog
# Chunk 16
qog %>%
{anyDuplicated(select(., cname,year)) == 0}
# Chunk 17
min(ged$year_cy)
max(ged$year_cy)
# Chunk 18
min(qog$year)
max(qog$year)
# Chunk 19
qog %>%
filter(year>=1989) -> qog
# Chunk 20
length(unique(ged$country_cy))
length(unique(qog$cname))
# Chunk 21
setdiff(ged$country_cy,qog$cname)
# Chunk 22
setdiff(qog$cname,ged$country_cy)
# Chunk 23
ged %>%
filter(!(country_cy %in% c("German Democratic Republic","Yemen (South Yemen)","Czechoslovakia"))) -> ged
# Chunk 24
ged$ccodecow <- countrycode::countrycode(ged$country_cy,
origin = "country.name.en",
destination = "cown")
# Chunk 25
ged %>%
relocate(country_cy,year_cy,ccodecow)
# Chunk 26
ged %>%
left_join(qog, by = c("ccodecow" = "ccodecow",
"year_cy" = "year")) -> merged
# Chunk 27
ncol(ged)
ncol(qog)
ncol(merged)
merged %>%
group_by(bmr_dem) %>%
summarise(sumdeaths = sum(sb_total_deaths_best_cy, na.rm = T)) %>%
drop_na(bmr_dem) %>%
ggplot(aes(x = factor(bmr_dem), y = sumdeaths)) +
geom_col() +
scale_y_continuous(labels = scales::label_number())
merged %>%
group_by(bmr_dem) %>%
summarise(sumdeaths = sum(sb_total_deaths_best_cy, na.rm = T)) %>%
drop_na(bmr_dem) %>%
ggplot(aes(x = factor(bmr_dem), y = sumdeaths)) +
geom_col() +
scale_y_continuous(labels = scales::label_number()) +
scale_x_discrete(labels = c("0" = "No", "1" = "Yes")) +
labs( x = "Democracy (Boix/Miller/Rosato)",
y = "Conflict fatalities")
merged %>%
group_by(bmr_dem) %>%
summarise(sumdeaths = sum(sb_total_deaths_best_cy, na.rm = T)) %>%
drop_na(bmr_dem) %>%
ggplot(aes(x = factor(bmr_dem), y = sumdeaths)) +
geom_col() +
scale_y_continuous(labels = scales::label_number()) +
scale_x_discrete(labels = c("0" = "No", "1" = "Yes")) +
labs( x = "Democracy (Boix/Miller/Rosato)",
y = "Conflict fatalities")
merged %>%
group_by(bmr_dem) %>%
summarise(sumdeaths = sum(sb_total_deaths_best_cy, na.rm = T)) %>%
drop_na(bmr_dem) %>%
ggplot(aes(x = factor(bmr_dem), y = sumdeaths)) +
geom_col() +
scale_y_continuous(labels = scales::label_number()) +
scale_x_discrete(labels = c("0" = "No", "1" = "Yes")) +
labs( x = "Democracy (Boix/Miller/Rosato)",
y = "Avg. conflict fatalities/year")
